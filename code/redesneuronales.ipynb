{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Redes neuronales con Pytorch y Tensorflow\n"
      ],
      "metadata": {
        "id": "zYmiHPeCD1zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch y TensorFlow son bibliotecas de código abierto ampliamente utilizadas para la computación numérica y el desarrollo de modelos de aprendizaje profundo. PyTorch, desarrollado por Facebook's AI Research lab (FAIR), y TensorFlow, creado por Google Brain, ofrecen potentes herramientas para el desarrollo y entrenamiento de redes neuronales.\n",
        "\n",
        "Ambas bibliotecas tienen como característica central el uso de tensores, que son estructuras de datos multidimensionales utilizadas para almacenar y manipular datos de manera eficiente. Los tensores en PyTorch y TensorFlow son similares a los arreglos de NumPy, pero tienen la ventaja de poder realizar operaciones en GPUs (Unidades de Procesamiento Gráfico), lo que permite una aceleración significativa en tareas computacionales intensivas, como el entrenamiento de redes neuronales.\n",
        "\n",
        "Mientras que PyTorch se destaca por su flexibilidad y una sintaxis más intuitiva, que facilita la depuración y el desarrollo rápido de modelos, TensorFlow es conocido por su robustez en producción, su capacidad para escalar, y por ofrecer TensorFlow Serving para implementar modelos en producción."
      ],
      "metadata": {
        "id": "VRWsbSQsD59i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ekYcfunuhvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch\n",
        "\n"
      ],
      "metadata": {
        "id": "KjOoGSVPuiFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ],
      "metadata": {
        "id": "soOPufKyBncU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manejo de tensores"
      ],
      "metadata": {
        "id": "jhOAbizTulgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8CQYgAko5mY"
      },
      "outputs": [],
      "source": [
        "list_a = [1,2,3,4]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor(list_a)"
      ],
      "metadata": {
        "id": "gT0L3hEDEW3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a"
      ],
      "metadata": {
        "id": "onabrHIrEalx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_a = [[1, 1, 1],\n",
        "       [2, 3, 4],\n",
        "       [4, 5, 6]]"
      ],
      "metadata": {
        "id": "_lR2EHhiEpJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_b = [[7, 5, 4],\n",
        "       [2, 2, 8],\n",
        "       [6, 3, 8]]"
      ],
      "metadata": {
        "id": "RdM_29PRD44a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor(array_a)\n",
        "tensor_b = torch.tensor(array_b)"
      ],
      "metadata": {
        "id": "9JsXc2oVElUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_c = tensor_a -tensor_b\n",
        "\n",
        "tensor_d = tensor_a * tensor_b\n",
        "\n",
        "tensor_e = tensor_c + tensor_d\n",
        "print(tensor_e)"
      ],
      "metadata": {
        "id": "aPHFfnzLEzoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manejo de capas"
      ],
      "metadata": {
        "id": "yUVyO92turjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.nn` es un módulo fundamental de PyTorch que proporciona herramientas y clases para construir y entrenar redes neuronales de manera eficiente. Este módulo simplifica el proceso de definición, implementación y entrenamiento de modelos de aprendizaje profundo al ofrecer una variedad de componentes predefinidos que se pueden combinar para crear arquitecturas de redes complejas.\n"
      ],
      "metadata": {
        "id": "1ctCa2NBFHiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
        "\n",
        "linear_layer = nn.Linear(in_features=8, out_features=3)"
      ],
      "metadata": {
        "id": "7iYg1Lp8E4WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer(input_tensor)"
      ],
      "metadata": {
        "id": "LHalB6R4FeIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con nn.Sequential podemos crear modelos completos"
      ],
      "metadata": {
        "id": "x2wvjiOMFdFB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S_jVUJCKFB_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(8, 8),\n",
        "                      nn.Linear(8, 1)\n",
        "                     )\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "eUUXTclxFCCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(8, 5),\n",
        "                      nn.Linear(5, 1)\n",
        "                     )\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "fBqq-6LIFsDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DapFKwxAFwET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funciones de activación"
      ],
      "metadata": {
        "id": "Hy7NExpVF29K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.tensor([[0.8]])\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "probability = sigmoid(input_tensor)\n",
        "print(probability)"
      ],
      "metadata": {
        "id": "pP5pVXnlF5rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
        "\n",
        "model = nn.Sequential(\n",
        "  nn.Linear(8,1),\n",
        "  nn.Sigmoid()\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "dXeNfP7qGHMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITpfQylTMRBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo con dataset vinos"
      ],
      "metadata": {
        "id": "bfedVUDuF9_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('winequality-red.csv')"
      ],
      "metadata": {
        "id": "ONVo5PCQBqff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['quality'])\n",
        "y = data['quality']\n",
        "\n",
        "# Estandarizar las características\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "FSo-DkEABxVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_encoded, dtype=torch.long)"
      ],
      "metadata": {
        "id": "bTsFSnwLMhmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ROnUN0CdMmm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "num_classes =  len(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "t8BpCxGZMpIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size, num_classes"
      ],
      "metadata": {
        "id": "KDHa0XNZMzsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, 64),  # Capa oculta 1\n",
        "    nn.ReLU(),                  # Función de activación ReLU\n",
        "    nn.Linear(64, 32),          # Capa oculta 2\n",
        "    nn.ReLU(),                  # Función de activación ReLU\n",
        "    nn.Linear(32, num_classes),  # Capa de salida\n",
        "    nn.Softmax(dim=-1)\n",
        ")"
      ],
      "metadata": {
        "id": "1da-NAU3Nikm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "-mvvFHjBM2k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujbeHKe-PiA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "\n",
        "    # Calcular la pérdida\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "k9FzFNtJNRH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Poner el modelo en modo de evaluación\n",
        "with torch.no_grad():  # No calcular gradientes\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)  # Obtener las predicciones\n",
        "    f1_micro = f1_score(y_test.numpy(), predicted.numpy(), average='micro')  # Calcular F1 micro"
      ],
      "metadata": {
        "id": "UOF-NbpsPZ1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'F1 Micro: {f1_micro:.4f}')"
      ],
      "metadata": {
        "id": "2jt4YceBQW7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-LJeYG3-QjWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, 64),\n",
        "    nn.BatchNorm1d(64),         # Batch Normalization\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.3),         # Dropout layer\n",
        "\n",
        "    nn.Linear(64, 32),\n",
        "    nn.BatchNorm1d(32),         # Batch Normalization\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.3),         # Dropout layer\n",
        "\n",
        "    nn.Linear(32, 16),\n",
        "    nn.BatchNorm1d(16),          # Batch Normalization\n",
        "    nn.LeakyReLU(negative_slope=0.01),\n",
        "    nn.Dropout(p=0.3),         # Dropout layer\n",
        "\n",
        "    nn.Linear(16, num_classes),\n",
        "    nn.Softmax(dim=-1)         # Softmax activation\n",
        ")"
      ],
      "metadata": {
        "id": "akKkiGEpQnjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "nAc2wXYPinta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10000\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "\n",
        "    # Calcular la pérdida\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "fFubbMZCSGYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Poner el modelo en modo de evaluación\n",
        "with torch.no_grad():  # No calcular gradientes\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)  # Obtener las predicciones\n",
        "    f1_micro = f1_score(y_test.numpy(), predicted.numpy(), average='micro')  # Calcular F1 micro"
      ],
      "metadata": {
        "id": "ihwQ7uzCTo4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'F1 Micro: {f1_micro:.4f}')"
      ],
      "metadata": {
        "id": "ebcvkQl3TsQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9RFhOIIpVP1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "em3gg4wlU5M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(X_train, y_train)"
      ],
      "metadata": {
        "id": "Bd5Fa-gqTvkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 300\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "AbLZL-unTvnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, 64),\n",
        "    nn.BatchNorm1d(64),         # Batch Normalization\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.2),         # Dropout layer\n",
        "\n",
        "    nn.Linear(64, 32),\n",
        "    nn.BatchNorm1d(32),         # Batch Normalization\n",
        "    nn.ReLU(),                          # Dropout layer\n",
        "\n",
        "    nn.Linear(32, 16),\n",
        "    nn.BatchNorm1d(16),          # Batch Normalization\n",
        "    nn.LeakyReLU(negative_slope=0.01),        # Dropout layer\n",
        "\n",
        "    nn.Linear(16, num_classes),\n",
        "    nn.Softmax(dim=-1)         # Softmax activation\n",
        ")"
      ],
      "metadata": {
        "id": "V238FiL6VQ5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "# Definir el optimizador y la función de pérdida\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,  weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "WyUFNtZziuw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "\n",
        "# Entrenar el modelo\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Cambiar el modelo a modo de entrenamiento\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()  # Limpiar los gradientes\n",
        "        outputs = model(inputs)  # Pasar los datos por el modelo\n",
        "        loss = criterion(outputs, labels)  # Calcular la pérdida\n",
        "        loss.backward()  # Calcular los gradientes\n",
        "        optimizer.step()  # Actualizar los parámetros\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Imprimir el promedio de pérdida de cada época\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "id": "hCdjWQMvTvsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AkUDJz6ZawZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Poner el modelo en modo de evaluación\n",
        "with torch.no_grad():  # No calcular gradientes\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)  # Obtener las predicciones\n",
        "    f1_micro = f1_score(y_test.numpy(), predicted.numpy(), average='micro')"
      ],
      "metadata": {
        "id": "NUM1ka25Z95m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f14Vfv6Hi-q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'F1 Micro: {f1_micro:.4f}')"
      ],
      "metadata": {
        "id": "s5wCP4CgaiIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XVYNqXvaxrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nVbCfii_axzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBZZIq0LjPYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py"
      ],
      "metadata": {
        "id": "J53e_1d6luJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kwQhe_xPlvPz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVUrN_mGIYU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow"
      ],
      "metadata": {
        "id": "K-HDGiN3IY5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este cuaderno, utilizaremos TensorFlow para abordar un problema de regresión, prediciendo la eficiencia del consumo de combustible de automóviles (medida en millas por galón, MPG) utilizando el conjunto de datos Auto MPG. Este dataset proviene de la base de datos de aprendizaje automático del UCI Machine Learning Repository y contiene diversas características técnicas de autos, como el número de cilindros, desplazamiento del motor, potencia, y peso."
      ],
      "metadata": {
        "id": "k-y3y06rIc6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "S5qeuNmZh8sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path"
      ],
      "metadata": {
        "id": "ebRVSQh3h9oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ],
      "metadata": {
        "id": "HJjX8kioiN2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.dropna()"
      ],
      "metadata": {
        "id": "tcbPwfubiWmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "origin = dataset.pop('Origin')"
      ],
      "metadata": {
        "id": "0aMRFUkcibHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ],
      "metadata": {
        "id": "92wQLNbQibKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "metadata": {
        "id": "9eeQ6HrbihJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")"
      ],
      "metadata": {
        "id": "13Rbi4kBinjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "metadata": {
        "id": "uAo0dtlGiywT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ],
      "metadata": {
        "id": "2UkHowUIir18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "metadata": {
        "id": "HKoFMS_3iu9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "TrjNvHqzjC_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "XClVJkLfjJd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "9AoXIliIjPo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch = normed_train_data[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result"
      ],
      "metadata": {
        "id": "ZO9XkpeejSTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "metadata": {
        "id": "_Wi7HwbdjZuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n"
      ],
      "metadata": {
        "id": "aSTgi0nsjiJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mae'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "fMpLfPDElyMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "S6YuY6t0l58z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ],
      "metadata": {
        "id": "E0CDWkPantzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}