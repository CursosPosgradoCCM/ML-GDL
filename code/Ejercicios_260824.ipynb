{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c37e16e-a990-4a74-aa59-fdf2a7e7253a",
   "metadata": {},
   "source": [
    "# Ejercicio 1: Regresión lineal\n",
    "\n",
    "Ajustar un modelo de regresión lineal simple. Realizarlos tanto a mano y en python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7040cf0-1d80-44d3-b23e-fa6d42b74db0",
   "metadata": {},
   "source": [
    "Supón que tienes un conjunto de datos que relaciona las horas de estudio con las notas obtenidas en un examen. La tabla de datos es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2871592e-780a-4331-a833-61880a955045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horas Estudio</th>\n",
       "      <th>Nota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Horas Estudio  Nota\n",
       "0              1    50\n",
       "1              2    53\n",
       "2              3    58\n",
       "3              4    60\n",
       "4              5    63\n",
       "5              6    65\n",
       "6              7    70"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33d12bc-33db-443e-9f41-63a1249ef551",
   "metadata": {},
   "source": [
    "Queremos ajustar un modelo de regresión lineal simple de la forma:\n",
    "$$Nota = \\beta_0 + \\beta_1 \\cdot Horas \\text{ Estudio} + \\epsilon$$\n",
    "donde:\n",
    "\n",
    "$\\beta_0$ es el término constante.\n",
    "\n",
    "$\\beta_1$ es el coeficiente de Horas Estudio\n",
    "\n",
    "Además, ya sabemos que:\n",
    "\n",
    "$$\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}, $$\n",
    "$$ \\beta_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} = \\frac{S_{xy}}{S_{xx}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc887708-026b-4824-9921-ec48713a2c97",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Regresión Múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba2af4-653d-450a-88bf-fd2a49037f5d",
   "metadata": {},
   "source": [
    "Analiza la relación entre varias variables independientes y una variable dependiente utilizando regresión múltiple.\n",
    "\n",
    "Supongamos que tienes datos sobre el número de horas estudiadas, el número de días asistidos a clase y la calificación obtenida.\n",
    "\n",
    "| Horas Estudiadas | Días Asistidos | Calificación |\n",
    "|------------------|----------------|--------------|\n",
    "| 1                | 5              | 50           |\n",
    "| 2                | 6              | 55           |\n",
    "| 3                | 7              | 60           |\n",
    "| 4                | 8              | 65           |\n",
    "| 5                | 9              | 70           |\n",
    "\n",
    "\n",
    "1. **Construye el modelo de regresión múltiple** $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$ donde $y$ es la calificación, $x_1$ es el número de horas estudiadas y $x_2$ es el número de días asistidos.\n",
    "   - Calcula la matriz $X$ de variables independientes y la matriz $y$ de variables dependientes.\n",
    "   - Utiliza la fórmula de los mínimos cuadrados para obtener los coeficientes:\n",
    "\n",
    "     $$\\beta = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "2. **Predice** la calificación para 4 horas de estudio y 8 días asistidos usando la ecuación obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c195c1-70c4-451d-bc54-8c960474c2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes de regresión:\n",
      "const              3.888889\n",
      "Horas Estudio     -5.277778\n",
      "Dias asistidos    10.277778\n",
      "dtype: float64\n",
      "\n",
      "Predicciones para los nuevos datos:\n",
      "0    65.0\n",
      "dtype: float64\n",
      "\n",
      "Resumen del modelo:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Nota   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 7.428e+30\n",
      "Date:                Tue, 27 Aug 2024   Prob (F-statistic):           1.09e-46\n",
      "Time:                        14:26:37   Log-Likelihood:                 158.09\n",
      "No. Observations:                   5   AIC:                            -312.2\n",
      "Df Residuals:                       3   BIC:                            -313.0\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              3.8889   1.06e-15   3.67e+15      0.000       3.889       3.889\n",
      "Horas Estudio     -5.2778   3.01e-15  -1.75e+15      0.000      -5.278      -5.278\n",
      "Dias asistidos    10.2778   1.26e-15   8.15e+15      0.000      10.278      10.278\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.500\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.839\n",
      "Skew:                          -0.408   Prob(JB):                        0.657\n",
      "Kurtosis:                       1.167   Cond. No.                     8.64e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.19e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johanna/anaconda3/lib/python3.9/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "# Esta libreria hace uso del metodo OLS(Ordinary Least Squares (Mínimos Cuadrados Ordinarios). \n",
    "#Este  método de ajuste se utiliza para estimar los coeficientes de un modelo de regresión lineal.\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = {\n",
    "    'Horas Estudio': [1, 2, 3, 4, 5],\n",
    "    'Dias asistidos': [5, 6, 7, 8, 9],\n",
    "    'Nota': [50, 55, 60, 65, 70]\n",
    "}\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Definir variables independientes (X) y dependientes (y)\n",
    "X = df[['Horas Estudio', 'Dias asistidos']]\n",
    "y = df['Nota']\n",
    "\n",
    "# Agregar constante para el término de intersección\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo OLS\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Obtener los coeficientes de regresión\n",
    "coefficients = model.params\n",
    "\n",
    "# Imprimir los coeficientes\n",
    "print(\"Coeficientes de regresión:\")\n",
    "print(coefficients)\n",
    "\n",
    "\n",
    "# Hacer la predicción\n",
    "nuevos_datos = pd.DataFrame({\n",
    "    'const': [1],  # Agregar el término constante\n",
    "    'Horas Estudio': [4],\n",
    "    'Dias asistidos': [8]\n",
    "})\n",
    "\n",
    "predicciones = model.predict(nuevos_datos)\n",
    "\n",
    "\n",
    "print(\"\\nPredicciones para los nuevos datos:\")\n",
    "print(predicciones)\n",
    "\n",
    "# Imprimir el resumen del modelo\n",
    "print(\"\\nResumen del modelo:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4cf3b-30ac-4acd-93cf-fd206491b1fe",
   "metadata": {},
   "source": [
    "# Ejercicio 3: Clusters\n",
    "\n",
    "Carga la base de datos USArrests. Obtén los dendrogramas y compara cuales realizan una mejor agrupación. ¿Cuál es el número óptimo de clusters?\n",
    "\n",
    "- Single linkage agglomerative clustering o método de la liga sencilla o del vecino más cercano.\n",
    "- Complete linkage agglomerative clustering o método de la liga completa o del vecino más lejano.\n",
    "- Average linkage agglomerative clustering o métdod de la liga promedio.\n",
    "- Ward’s minimum variance clustering o método Ward.\n",
    "- kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28195b5-546b-4b68-87eb-a2f113d9582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /opt/tljh/user/lib/python3.10/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/tljh/user/lib/python3.10/site-packages (from statsmodels) (1.13.1)\n",
      "Collecting pandas!=2.1.0,>=1.4 (from statsmodels)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/tljh/user/lib/python3.10/site-packages (from statsmodels) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/tljh/user/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas!=2.1.0,>=1.4->statsmodels)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas!=2.1.0,>=1.4->statsmodels)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six in /opt/tljh/user/lib/python3.10/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, patsy, pandas, statsmodels\n",
      "Successfully installed pandas-2.2.2 patsy-0.5.6 pytz-2024.1 statsmodels-0.14.2 tzdata-2024.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00bf87d0-bcdc-43d9-ab13-f84b8efeb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yellowbrick\n",
      "  Using cached yellowbrick-1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting matplotlib!=3.0.0,>=2.0.2 (from yellowbrick)\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/tljh/user/lib/python3.10/site-packages (from yellowbrick) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/tljh/user/lib/python3.10/site-packages (from yellowbrick) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/tljh/user/lib/python3.10/site-packages (from yellowbrick) (1.26.4)\n",
      "Collecting cycler>=0.10.0 (from yellowbrick)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.0.0,>=2.0.2->yellowbrick)\n",
      "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.0.0,>=2.0.2->yellowbrick)\n",
      "  Downloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib!=3.0.0,>=2.0.2->yellowbrick)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/tljh/user/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib!=3.0.0,>=2.0.2->yellowbrick)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.0.0,>=2.0.2->yellowbrick)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/tljh/user/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/tljh/user/lib/python3.10/site-packages (from scikit-learn>=1.0.0->yellowbrick) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/tljh/user/lib/python3.10/site-packages (from scikit-learn>=1.0.0->yellowbrick) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n",
      "Using cached yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, yellowbrick\n",
      "\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/home/jupyter-user9/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.53.1 kiwisolver-1.4.5 matplotlib-3.9.2 pillow-10.4.0 pyparsing-3.1.4 yellowbrick-1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3348c388-21a9-4392-80f8-ab2a2d8499f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from statsmodels.datasets import get_rdataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances, ConfusionMatrixDisplay \n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "data = get_rdataset('USArrests', package='datasets').data\n",
    "df = data.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5958e3c-82e3-4ee0-851f-49b1537afd5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linkage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m single \u001b[38;5;241m=\u001b[39m \u001b[43mlinkage\u001b[49m(df, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m complete \u001b[38;5;241m=\u001b[39m linkage(df, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m avg \u001b[38;5;241m=\u001b[39m linkage(df, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linkage' is not defined"
     ]
    }
   ],
   "source": [
    "single = linkage(df, method='single')\n",
    "complete = linkage(df, method='complete')\n",
    "avg = linkage(df, method='average')\n",
    "ward = linkage(df, method='ward')\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "dendrogram(single,\n",
    "           orientation='top',\n",
    "           distance_sort='descending',\n",
    "           show_leaf_counts=True)\n",
    "plt.title('Dendrograma del Clustering Jerárquico')\n",
    "plt.xlabel('Puntos de datos')\n",
    "plt.ylabel('Distancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205c858-f661-428b-a916-97c960f5ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "dendrogram(complete,\n",
    "           orientation='top',\n",
    "           distance_sort='descending',\n",
    "           show_leaf_counts=True)\n",
    "plt.title('Dendrograma del Clustering Jerárquico')\n",
    "plt.xlabel('Puntos de datos')\n",
    "plt.ylabel('Distancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a626a-efa9-4809-8c53-f4e538fe794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "dendrogram(avg,\n",
    "           orientation='top',\n",
    "           distance_sort='descending',\n",
    "           show_leaf_counts=True)\n",
    "plt.title('Dendrograma del Clustering Jerárquico')\n",
    "plt.xlabel('Puntos de datos')\n",
    "plt.ylabel('Distancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e685f-725d-4c70-b41c-7af57429b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "dendrogram(ward,\n",
    "           orientation='top',\n",
    "           distance_sort='descending',\n",
    "           show_leaf_counts=True)\n",
    "plt.title('Dendrograma del Clustering Jerárquico')\n",
    "plt.xlabel('Puntos de datos')\n",
    "plt.ylabel('Distancia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f1c51-f4d4-4229-a9d6-e0d3f6a431f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "labels = kmeans.fit_predict(x_scaled)\n",
    "\n",
    "plt.scatter(x_scaled[:,0], x_scaled[:,1], c = labels, cmap ='viridis')\n",
    "plt.xlabel(df.columns[0])\n",
    "plt.ylabel(df.columns[1])\n",
    "plt.title('K-Means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884f9af-42ac-4594-b7bd-92c46e8602da",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = KElbowVisualizer(kmeans, k=(2,10))\n",
    " \n",
    "visualizer.fit(x_scaled)  # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616c454-5cc5-4978-8f7c-bcc5c254852c",
   "metadata": {},
   "source": [
    "# Ejercicio 4: Clusters\n",
    "\n",
    "Aplicar diferentes técnicas de clusterización jerárquica al conjunto de datos de vino y comparar los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed17b29a-9a5e-46a9-9782-9e1da0b66f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Carga de datos\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "feature_names = data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed387b-4cfe-4d66-8524-1566b03eaa27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e219c0-b5b0-4c9e-91e6-f8cbdafced79",
   "metadata": {},
   "source": [
    "# Ejercicio 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356cb9c-61f6-4320-b165-42eaf48a88f4",
   "metadata": {},
   "source": [
    "Supongamos que eres un investigador que quiere clasificar mensajes de texto como \"spam\" o \"no spam\" basándote en la presencia de ciertas palabras clave. Tienes un conjunto pequeño de datos con 6 mensajes de texto etiquetados como \"spam\" o \"no spam\". Las palabras clave que estás considerando son: **\"oferta\"** y **\"gratis\"**.\n",
    "\n",
    "| Mensaje                              | Contiene \"oferta\" | Contiene \"gratis\" | Etiqueta |\n",
    "|--------------------------------------|-------------------|-------------------|----------|\n",
    "| \"Ofertas especiales hoy\"             | Sí                | No                | Spam     |\n",
    "| \"Llama ahora para obtener tu oferta\" | Sí                | No                | Spam     |\n",
    "| \"Descarga gratis\"                    | No                | Sí                | Spam     |\n",
    "| \"Agenda tu cita gratis\"              | No                | Sí                | No spam  |\n",
    "| \"Ofertas limitadas\"                  | Sí                | No                | No spam  |\n",
    "| \"Envía gratis ahora\"                 | No                | Sí                | No spam  |\n",
    "\n",
    "**Pregunta:** Dado un nuevo mensaje que contiene **\"oferta\"** pero no contiene **\"gratis\"**, ¿es más probable que sea \"spam\" o \"no spam\"? Utiliza Naive Bayes para resolverlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975feda4-c581-4b2f-9773-c74d474ac9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {\n",
    "    'Contiene \"oferta\"': ['Sí','Sí','No','No','Sí','No',],\n",
    "    'Contiene \"gratis\"': ['No','No','Sí','Sí','No','Sí',],\n",
    "    'Etiqueta' : ['Spam','Spam','Spam','No spam','No spam','No spam']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df[df=='Sí']=1 #Se cambia a variables númericas. 1 es Sí, 2 es No\n",
    "df[df=='No']=0 #para varibales de respuesta 1 es Spam y 2 es No spam\n",
    "df[df=='Spam']=1\n",
    "df[df=='No spam']=0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66226e-7e2d-4a85-b825-1da221d5c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eligen las primeras dos columnas del data frame para las variables de entrada y cambian a tipo entero. P\n",
    "#La ultima columna corresponde a la variable Y\n",
    "X_train=df[['Contiene \"oferta\"','Contiene \"gratis\"']].values.astype('int32')\n",
    "y_train=df['Etiqueta'].values.astype('int32')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb847ea-9ace-4f3a-b45a-e6d3e3348f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB #Importa Naive bayes\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3349c2-229b-42c4-a085-394716ad1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predice para \n",
    "clf.predict([[1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8226a9cf-4c96-4513-8138-17b4730b3b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje 'oferta' es más probable que sea: spam\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "mensajes = [\n",
    "    \"Ofertas especiales hoy\",\n",
    "    \"Llama ahora para obtener tu oferta\",\n",
    "    \"Descarga gratis\",\n",
    "    \"Agenda tu cita gratis\",\n",
    "    \"Ofertas limitadas\",\n",
    "    \"Envía gratis ahora\"\n",
    "]\n",
    "\n",
    "etiquetas = [\"spam\", \"spam\", \"spam\", \"no spam\", \"no spam\", \"no spam\"]\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=[\"oferta\", \"gratis\"])\n",
    "X = vectorizer.transform(mensajes).toarray()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(etiquetas)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(X, y)\n",
    "\n",
    "nuevo_mensaje = [\"oferta\"]\n",
    "X_nuevo = vectorizer.transform(nuevo_mensaje).toarray()\n",
    "\n",
    "prediccion = modelo.predict(X_nuevo)\n",
    "etiqueta_predicha = label_encoder.inverse_transform(prediccion)\n",
    "\n",
    "print(f\"El mensaje '{nuevo_mensaje[0]}' es más probable que sea: {etiqueta_predicha[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ce3830-3c2b-4624-8a37-4488ecaf18d4",
   "metadata": {},
   "source": [
    "# Ejercicio 6: Clasificación de Correo Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0fa0b-aa86-48fb-b9ca-6a5859996a11",
   "metadata": {},
   "source": [
    "_Conjunto de Datos \"20 Newsgroups\"__\n",
    "\n",
    "__Tipo de Datos:__ Este conjunto de datos consiste en un conjunto de mensajes de texto tomados de 20 grupos de noticias diferentes en Usenet, que cubren una variedad de temas. Los mensajes están etiquetados con la categoría correspondiente a su grupo de noticias.\n",
    "\n",
    "__Número de Clases:__ Hay 20 categorías diferentes en el conjunto completo, pero en el ejemplo proporcionado, se limitan a dos categorías relacionadas con deportes: rec.sport.hockey y rec.sport.baseball.\n",
    "\n",
    "Este conjunto de datos se puede ocupar para tareas de clasificación de texto, como experimentos con algoritmos de machine learning para clasificación de documentos, clasificación de texto y análisis de sentimientos.\n",
    "\n",
    "newsgroups.data: Contiene los mensajes de texto reales.\n",
    "\n",
    "newsgroups.target: Contiene los índices numéricos de las categorías a las que pertenecen los mensajes.\n",
    "\n",
    "newsgroups.target_names: Es una lista de los nombres de las categorías, donde cada nombre corresponde al índice en newsgroups.target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e31c8f-f8bd-4438-be1a-71d3b20a9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Cargar un conjunto de datos de texto\n",
    "categories = ['rec.sport.hockey', 'rec.sport.baseball']\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb9d93-a78a-4a99-bc46-4cefae35dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver los primeros 5 mensajes y sus categorías\n",
    "for i in range(5):\n",
    "    print(f\"Mensaje {i+1}:\\n\")\n",
    "    print(newsgroups.data[i])\n",
    "    print(f\"\\nCategoría: {newsgroups.target_names[newsgroups.target[i]]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4fce9-6aaa-4489-9fdb-bd8ec8ce32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir texto a matriz de conteo de palabras\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "y = newsgroups.target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
