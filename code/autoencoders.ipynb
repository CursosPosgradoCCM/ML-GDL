{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBd8HU_P1CWa"
      },
      "source": [
        "# AutoEncoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxULxeI65Nq1"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Explore autoencoders first in numpy, then in keras (you can swithch the backend to pytorch or jax when ready).\n",
        "\n",
        "We look at a PCA, a linear autoencoder, and then a two layer autoencoder in `numpy`.\n",
        "\n",
        "Then a (flexible) AutoEncoder in keras. Then some hyperparameter tuning based on a suitable metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6AJxA5U7NFY"
      },
      "source": [
        "## Data\n",
        "\n",
        "Example data from [here](https://huggingface.co/datasets/simecek/human_nontata_promoters), more details [here](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0171410#sec002)\n",
        "\n",
        "It's human nontata promoters toy dataset.\n",
        "\n",
        "https://chatgpt.com/share/67227fc5-2688-8011-bb2e-e9095ce89d41\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_L0AkgeBHV-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "splits = {'train': 'data/train-00000-of-00001-9af6936029261ba1.parquet', 'test': 'data/test-00000-of-00001-5ba65be5fd0fb68f.parquet'}\n",
        "df = pd.read_parquet(\"hf://datasets/simecek/human_nontata_promoters/\" + splits[\"train\"])\n",
        "df = df.rename(columns={\"seq\": \"sequence\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4YW-OV0fCBSp",
        "outputId": "9f363f01-7191-4993-c9d2-ba1a5fd119c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 27097,\n  \"fields\": [\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27097,\n        \"samples\": [\n          \"TGAGTTATTTTGAGATTTCAGTTTTAACATTTTCTTCTATAATCCATGTGGCTGGGTTTTGGGATCTGGCTAACCCCCGCCATGCCAGTAGCCTGAGGGGCCCAGCCCCACTTGTTGAACAGCCGCTCTCCCCGCCCCACCCACCCTGCCTGCCTGCCCACCCGCCCTGGTCTCTCCAGGAATCATGTTCGTTCAGGAGGAGGCCCTGGCCAGCAGCCTCTCGTCCACTGACAGTCTGACTCCCGAGCACC\",\n          \"ACCTTAGAAGTCTGTGCCCTTACCCATCACAGCCTCATCCTTATCTCCTCCATTCCCTAGGGGACTTAACAGGTGTTGAAATTATTACAGAGAAAGCTGACTCACTCACCAGGAATCTGATCCTGCTGTGGGCTGGCTTGGGTGGAGGTGTTCCTCCCGCCCCCGCACCCATCCTCCTGTTTGAACTCAGGCTGCTGCCTGCTGGGCCTGCCTGCCCTTGGAGCCCTGCTGAGCTCAGCCTGAGGCCTGGC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-13a4248d-a0f9-4615-ae00-b7465142c312\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ACAGATTCAGGATGTCCTGTCGGGGCATGGACCCTGGAAAGCTGCG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ATGATTTTAATACCACATTGGTAGACCTGCAATCCCCCAGAGAAGG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>CCCCGGGATGCCCCTAGCCCCTCCCTGTGAGCTGCCTCTCACAGGT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>GACCACCAGGGTGAGCTGGGGGTGGGCGGGGCCTGCCTGGCCAGGG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>TTTTCCAGAAAATGAGGTGTGGCCAAACATCTTCAGGCTTTTCCTT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13a4248d-a0f9-4615-ae00-b7465142c312')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13a4248d-a0f9-4615-ae00-b7465142c312 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13a4248d-a0f9-4615-ae00-b7465142c312');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01371ca9-df49-49f8-869b-a8f7b613b8ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01371ca9-df49-49f8-869b-a8f7b613b8ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01371ca9-df49-49f8-869b-a8f7b613b8ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   labels                                           sequence\n",
              "0       0  ACAGATTCAGGATGTCCTGTCGGGGCATGGACCCTGGAAAGCTGCG...\n",
              "1       0  ATGATTTTAATACCACATTGGTAGACCTGCAATCCCCCAGAGAAGG...\n",
              "2       0  CCCCGGGATGCCCCTAGCCCCTCCCTGTGAGCTGCCTCTCACAGGT...\n",
              "3       0  GACCACCAGGGTGAGCTGGGGGTGGGCGGGGCCTGCCTGGCCAGGG...\n",
              "4       0  TTTTCCAGAAAATGAGGTGTGGCCAAACATCTTCAGGCTTTTCCTT..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psVkEpqeCwmY",
        "outputId": "6c14fa47-f61d-440e-f937-7540236a18b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count                                                 27097\n",
            "unique                                                27097\n",
            "top       ACAGATTCAGGATGTCCTGTCGGGGCATGGACCCTGGAAAGCTGCG...\n",
            "freq                                                      1\n",
            "Name: sequence, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Summary statistics\n",
        "print(df['sequence'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NcyshFUQpWC",
        "outputId": "8e6d1792-3828-4db8-db0c-184d787d1cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique characters: {'T', 'G', 'A', 'C'}\n"
          ]
        }
      ],
      "source": [
        "unique_characters = set().union(*df['sequence'])\n",
        "print(f\"Unique characters: {unique_characters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r1er0NSVrEn",
        "outputId": "88899e4d-0c8c-4e07-a2f4-05d245603a30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sequences: \n",
            " [['A', 'C', 'A', 'G', 'A', 'T', 'T', 'C', 'A', 'G', 'G', 'A', 'T', 'G', 'T', 'C', 'C', 'T', 'G', 'T', 'C', 'G', 'G', 'G', 'G', 'C', 'A', 'T', 'G', 'G', 'A', 'C', 'C', 'C', 'T', 'G', 'G', 'A', 'A', 'A', 'G', 'C', 'T', 'G', 'C', 'G', 'G', 'A', 'C', 'A', 'C', 'C', 'A', 'G', 'G', 'A', 'G', 'G', 'G', 'C', 'A', 'G', 'G', 'C', 'A', 'A', 'G', 'A', 'G', 'A', 'G', 'T', 'C', 'T', 'C', 'A', 'T', 'C', 'T', 'C', 'T', 'T', 'G', 'C', 'T', 'C', 'C', 'C', 'T', 'A', 'G', 'G', 'A', 'G', 'C', 'T', 'A', 'T', 'G', 'A', 'G', 'T', 'T', 'G', 'A', 'G', 'G', 'G', 'C', 'G', 'C', 'C', 'G', 'T', 'C', 'T', 'G', 'A', 'G', 'C', 'A', 'G', 'G', 'A', 'G', 'G', 'G', 'A', 'C', 'G', 'G', 'A', 'C', 'G', 'G', 'G', 'T', 'G', 'C', 'C', 'C', 'A', 'G', 'G', 'G', 'T', 'T', 'T', 'G', 'A', 'G', 'G', 'A', 'A', 'A', 'G', 'A', 'G', 'G', 'G', 'G', 'T', 'G', 'T', 'G', 'G', 'G', 'A', 'A', 'G', 'G', 'A', 'C', 'G', 'C', 'A', 'T', 'G', 'C', 'T', 'A', 'G', 'A', 'A', 'C', 'T', 'T', 'C', 'A', 'G', 'A', 'G', 'C', 'A', 'G', 'T', 'T', 'C', 'A', 'G', 'C', 'A', 'G', 'G', 'T', 'G', 'C', 'A', 'G', 'A', 'A', 'T', 'G', 'G', 'G', 'A', 'G', 'T', 'T', 'A', 'T', 'C', 'A', 'T', 'G', 'G', 'G', 'G', 'A', 'C', 'T', 'G', 'T', 'G', 'G', 'G', 'A', 'G', 'A', 'A', 'G', 'G', 'G', 'G', 'C', 'G', 'G', 'T', 'G', 'G', 'G'], ['A', 'T', 'G', 'A', 'T', 'T', 'T', 'T', 'A', 'A', 'T', 'A', 'C', 'C', 'A', 'C', 'A', 'T', 'T', 'G', 'G', 'T', 'A', 'G', 'A', 'C', 'C', 'T', 'G', 'C', 'A', 'A', 'T', 'C', 'C', 'C', 'C', 'C', 'A', 'G', 'A', 'G', 'A', 'A', 'G', 'G', 'A', 'A', 'C', 'A', 'T', 'C', 'C', 'T', 'G', 'G', 'G', 'A', 'T', 'G', 'T', 'A', 'C', 'T', 'T', 'A', 'G', 'A', 'G', 'A', 'C', 'C', 'T', 'C', 'A', 'G', 'T', 'A', 'A', 'A', 'C', 'C', 'T', 'T', 'A', 'T', 'G', 'T', 'G', 'T', 'C', 'T', 'T', 'T', 'G', 'C', 'T', 'C', 'C', 'C', 'C', 'C', 'A', 'A', 'A', 'T', 'T', 'A', 'A', 'C', 'A', 'G', 'G', 'G', 'A', 'T', 'A', 'G', 'G', 'G', 'T', 'A', 'T', 'T', 'C', 'T', 'C', 'T', 'T', 'T', 'G', 'A', 'A', 'T', 'A', 'G', 'A', 'A', 'A', 'A', 'T', 'A', 'A', 'G', 'G', 'A', 'A', 'A', 'A', 'G', 'A', 'A', 'G', 'G', 'T', 'G', 'T', 'C', 'T', 'G', 'T', 'C', 'T', 'T', 'A', 'C', 'A', 'A', 'C', 'T', 'A', 'A', 'T', 'A', 'A', 'T', 'C', 'A', 'T', 'G', 'A', 'T', 'A', 'G', 'A', 'C', 'A', 'G', 'A', 'G', 'C', 'T', 'G', 'A', 'T', 'G', 'A', 'T', 'A', 'T', 'T', 'C', 'A', 'G', 'C', 'T', 'A', 'G', 'T', 'C', 'T', 'C', 'C', 'A', 'T', 'G', 'C', 'T', 'T', 'G', 'G', 'T', 'C', 'A', 'G', 'T', 'C', 'A', 'T', 'C', 'T', 'G', 'C', 'T', 'T', 'A', 'T', 'T', 'T', 'A', 'C', 'A', 'G', 'C', 'C', 'A', 'G', 'G', 'A', 'C', 'C'], ['C', 'C', 'C', 'C', 'G', 'G', 'G', 'A', 'T', 'G', 'C', 'C', 'C', 'C', 'T', 'A', 'G', 'C', 'C', 'C', 'C', 'T', 'C', 'C', 'C', 'T', 'G', 'T', 'G', 'A', 'G', 'C', 'T', 'G', 'C', 'C', 'T', 'C', 'T', 'C', 'A', 'C', 'A', 'G', 'G', 'T', 'C', 'T', 'G', 'T', 'C', 'T', 'C', 'T', 'G', 'C', 'T', 'T', 'C', 'C', 'C', 'C', 'A', 'G', 'G', 'A', 'C', 'T', 'G', 'G', 'T', 'G', 'G', 'A', 'G', 'G', 'G', 'T', 'C', 'T', 'G', 'C', 'G', 'G', 'A', 'A', 'G', 'C', 'G', 'C', 'C', 'T', 'G', 'C', 'T', 'G', 'C', 'C', 'G', 'G', 'C', 'C', 'T', 'G', 'G', 'T', 'G', 'T', 'G', 'C', 'C', 'T', 'C', 'C', 'C', 'T', 'G', 'G', 'C', 'C', 'C', 'A', 'C', 'G', 'G', 'G', 'C', 'T', 'C', 'A', 'G', 'C', 'C', 'T', 'G', 'C', 'T', 'C', 'C', 'T', 'G', 'G', 'T', 'G', 'G', 'C', 'T', 'G', 'T', 'G', 'G', 'C', 'T', 'G', 'T', 'G', 'G', 'C', 'T', 'G', 'T', 'C', 'T', 'C', 'A', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'T', 'G', 'C', 'G', 'A', 'G', 'C', 'T', 'T', 'C', 'C', 'C', 'C', 'C', 'C', 'G', 'G', 'G', 'C', 'G', 'T', 'G', 'A', 'G', 'T', 'G', 'T', 'T', 'G', 'C', 'G', 'T', 'G', 'G', 'C', 'T', 'C', 'C', 'T', 'G', 'T', 'C', 'C', 'A', 'G', 'C', 'A', 'G', 'C', 'G', 'C', 'C', 'A', 'G', 'C', 'T', 'T', 'C', 'C', 'T', 'G', 'G', 'C', 'C', 'T', 'C', 'A', 'T', 'T', 'C', 'C', 'T', 'C', 'G', 'G'], ['G', 'A', 'C', 'C', 'A', 'C', 'C', 'A', 'G', 'G', 'G', 'T', 'G', 'A', 'G', 'C', 'T', 'G', 'G', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'C', 'G', 'G', 'G', 'G', 'C', 'C', 'T', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'C', 'A', 'G', 'G', 'G', 'A', 'G', 'T', 'G', 'T', 'G', 'A', 'G', 'G', 'G', 'A', 'C', 'A', 'A', 'G', 'G', 'G', 'C', 'C', 'A', 'C', 'C', 'C', 'C', 'C', 'A', 'G', 'G', 'G', 'C', 'C', 'T', 'G', 'G', 'G', 'A', 'G', 'T', 'G', 'G', 'C', 'C', 'G', 'A', 'G', 'C', 'T', 'G', 'G', 'A', 'T', 'G', 'G', 'C', 'C', 'C', 'C', 'G', 'A', 'C', 'T', 'G', 'A', 'G', 'T', 'A', 'G', 'G', 'G', 'A', 'A', 'C', 'T', 'G', 'A', 'G', 'T', 'A', 'G', 'G', 'G', 'A', 'A', 'C', 'A', 'G', 'A', 'T', 'C', 'T', 'G', 'A', 'G', 'G', 'A', 'C', 'A', 'A', 'G', 'C', 'T', 'C', 'T', 'G', 'G', 'A', 'A', 'T', 'T', 'C', 'C', 'T', 'C', 'A', 'T', 'T', 'G', 'A', 'G', 'A', 'C', 'C', 'A', 'G', 'A', 'G', 'G', 'T', 'G', 'G', 'C', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'G', 'G', 'T', 'G', 'G', 'C', 'C', 'T', 'G', 'G', 'G', 'G', 'G', 'C', 'T', 'C', 'T', 'G', 'T', 'C', 'T', 'C', 'T', 'G', 'A', 'G', 'A', 'C', 'C', 'T', 'T', 'G', 'G', 'C', 'C', 'T', 'T', 'C', 'T', 'G', 'C', 'C', 'T', 'C', 'C', 'C', 'C', 'C', 'C', 'A', 'G', 'A', 'C', 'T', 'A', 'T', 'G', 'C', 'G', 'G', 'A', 'G', 'G', 'C', 'C', 'C', 'T'], ['T', 'T', 'T', 'T', 'C', 'C', 'A', 'G', 'A', 'A', 'A', 'A', 'T', 'G', 'A', 'G', 'G', 'T', 'G', 'T', 'G', 'G', 'C', 'C', 'A', 'A', 'A', 'C', 'A', 'T', 'C', 'T', 'T', 'C', 'A', 'G', 'G', 'C', 'T', 'T', 'T', 'T', 'C', 'C', 'T', 'T', 'C', 'T', 'T', 'T', 'C', 'C', 'T', 'T', 'T', 'C', 'T', 'C', 'C', 'C', 'G', 'T', 'G', 'G', 'C', 'C', 'T', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'A', 'G', 'C', 'T', 'G', 'C', 'T', 'C', 'C', 'C', 'C', 'A', 'T', 'G', 'C', 'C', 'T', 'G', 'G', 'G', 'G', 'G', 'C', 'A', 'G', 'G', 'T', 'G', 'C', 'G', 'A', 'G', 'A', 'G', 'C', 'C', 'T', 'G', 'T', 'G', 'C', 'C', 'C', 'C', 'T', 'C', 'C', 'C', 'T', 'G', 'G', 'G', 'G', 'C', 'A', 'G', 'T', 'T', 'T', 'C', 'A', 'C', 'A', 'G', 'C', 'T', 'G', 'T', 'G', 'T', 'C', 'C', 'C', 'T', 'T', 'C', 'C', 'A', 'G', 'G', 'G', 'G', 'G', 'C', 'C', 'T', 'G', 'C', 'C', 'T', 'G', 'T', 'G', 'T', 'T', 'C', 'A', 'C', 'C', 'G', 'T', 'G', 'G', 'C', 'C', 'T', 'C', 'T', 'G', 'C', 'A', 'G', 'C', 'A', 'C', 'C', 'T', 'C', 'T', 'C', 'G', 'C', 'C', 'C', 'C', 'T', 'T', 'A', 'G', 'G', 'G', 'C', 'T', 'C', 'C', 'T', 'G', 'C', 'G', 'C', 'C', 'T', 'C', 'G', 'G', 'G', 'T', 'C', 'C', 'C', 'G', 'G', 'T', 'G', 'C', 'C', 'T', 'C', 'A', 'T', 'T', 'T', 'C', 'T', 'C', 'C', 'C', 'T', 'A', 'A', 'A', 'G', 'C', 'A', 'T', 'T', 'G'], ['A', 'C', 'T', 'A', 'T', 'G', 'G', 'C', 'A', 'A', 'G', 'G', 'A', 'C', 'C', 'T', 'G', 'A', 'T', 'G', 'G', 'A', 'G', 'A', 'A', 'G', 'G', 'T', 'C', 'A', 'A', 'G', 'A', 'G', 'C', 'C', 'C', 'A', 'G', 'A', 'G', 'C', 'T', 'T', 'C', 'A', 'G', 'G', 'C', 'C', 'G', 'A', 'G', 'G', 'C', 'C', 'A', 'A', 'G', 'T', 'A', 'A', 'G', 'T', 'C', 'T', 'C', 'A', 'G', 'G', 'G', 'C', 'A', 'A', 'G', 'G', 'G', 'G', 'T', 'T', 'C', 'A', 'G', 'G', 'G', 'G', 'C', 'T', 'G', 'T', 'G', 'G', 'A', 'A', 'C', 'T', 'G', 'T', 'G', 'G', 'A', 'G', 'A', 'G', 'A', 'A', 'A', 'G', 'A', 'A', 'G', 'G', 'G', 'A', 'A', 'G', 'A', 'T', 'G', 'A', 'G', 'A', 'G', 'G', 'T', 'C', 'C', 'C', 'A', 'C', 'A', 'G', 'A', 'A', 'G', 'T', 'C', 'T', 'G', 'A', 'A', 'C', 'C', 'C', 'A', 'G', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'G', 'A', 'T', 'T', 'A', 'G', 'G', 'G', 'C', 'A', 'G', 'A', 'T', 'T', 'A', 'G', 'G', 'C', 'T', 'T', 'A', 'A', 'A', 'T', 'T', 'G', 'C', 'A', 'G', 'A', 'G', 'A', 'A', 'A', 'A', 'A', 'G', 'T', 'A', 'T', 'T', 'T', 'C', 'A', 'T', 'C', 'A', 'C', 'C', 'C', 'A', 'A', 'A', 'G', 'A', 'T', 'C', 'C', 'C', 'A', 'C', 'A', 'C', 'G', 'T', 'C', 'T', 'C', 'T', 'T', 'A', 'G', 'A', 'T', 'A', 'G', 'A', 'G', 'A', 'G', 'G', 'A', 'A', 'C', 'A', 'G', 'C', 'A', 'A', 'G', 'A', 'A', 'C', 'T', 'G', 'G', 'G', 'C'], ['G', 'A', 'A', 'C', 'A', 'C', 'T', 'A', 'G', 'A', 'A', 'A', 'C', 'A', 'G', 'A', 'G', 'G', 'G', 'G', 'A', 'C', 'T', 'G', 'T', 'G', 'A', 'C', 'C', 'T', 'G', 'G', 'G', 'G', 'A', 'C', 'T', 'T', 'T', 'T', 'T', 'C', 'T', 'G', 'C', 'A', 'G', 'G', 'A', 'A', 'G', 'A', 'A', 'A', 'A', 'C', 'A', 'G', 'C', 'C', 'C', 'A', 'A', 'A', 'G', 'A', 'T', 'G', 'A', 'G', 'A', 'G', 'T', 'G', 'A', 'T', 'T', 'C', 'G', 'C', 'G', 'T', 'G', 'G', 'G', 'T', 'A', 'C', 'C', 'C', 'G', 'C', 'A', 'A', 'G', 'A', 'G', 'C', 'C', 'A', 'G', 'G', 'T', 'G', 'G', 'G', 'T', 'G', 'C', 'A', 'G', 'G', 'A', 'G', 'C', 'C', 'G', 'G', 'G', 'G', 'T', 'G', 'G', 'A', 'G', 'G', 'A', 'G', 'G', 'T', 'T', 'T', 'G', 'T', 'C', 'A', 'G', 'A', 'A', 'C', 'A', 'G', 'T', 'T', 'A', 'T', 'G', 'A', 'T', 'G', 'C', 'T', 'C', 'A', 'C', 'A', 'G', 'C', 'A', 'T', 'C', 'A', 'C', 'A', 'A', 'A', 'T', 'T', 'G', 'G', 'G', 'G', 'G', 'A', 'C', 'T', 'C', 'A', 'G', 'A', 'G', 'G', 'G', 'T', 'T', 'A', 'G', 'T', 'T', 'C', 'C', 'T', 'A', 'G', 'T', 'A', 'T', 'G', 'A', 'A', 'G', 'G', 'A', 'G', 'A', 'T', 'G', 'G', 'G', 'G', 'T', 'G', 'G', 'C', 'T', 'G', 'G', 'G', 'C', 'G', 'T', 'T', 'A', 'A', 'G', 'T', 'T', 'C', 'C', 'C', 'C', 'G', 'G', 'G', 'A', 'A', 'A', 'T', 'G', 'G', 'C', 'A', 'G', 'A', 'T', 'T', 'A', 'C', 'A', 'T', 'T'], ['T', 'T', 'G', 'G', 'T', 'T', 'G', 'A', 'T', 'G', 'G', 'A', 'C', 'A', 'C', 'T', 'T', 'A', 'G', 'G', 'T', 'T', 'G', 'G', 'T', 'T', 'C', 'C', 'T', 'T', 'A', 'T', 'C', 'T', 'T', 'T', 'G', 'C', 'A', 'A', 'T', 'T', 'G', 'T', 'G', 'A', 'A', 'T', 'T', 'G', 'T', 'G', 'C', 'T', 'G', 'C', 'C', 'T', 'A', 'T', 'A', 'A', 'A', 'C', 'A', 'T', 'G', 'T', 'G', 'T', 'G', 'T', 'G', 'C', 'A', 'T', 'G', 'T', 'A', 'C', 'C', 'T', 'T', 'T', 'T', 'T', 'C', 'A', 'T', 'A', 'T', 'A', 'A', 'T', 'G', 'A', 'C', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'C', 'C', 'T', 'T', 'T', 'G', 'G', 'G', 'T', 'A', 'G', 'A', 'T', 'A', 'G', 'C', 'C', 'A', 'G', 'T', 'A', 'G', 'T', 'G', 'G', 'A', 'A', 'T', 'T', 'T', 'C', 'T', 'G', 'G', 'A', 'T', 'T', 'G', 'A', 'A', 'T', 'G', 'G', 'T', 'A', 'G', 'A', 'T', 'A', 'G', 'A', 'T', 'G', 'G', 'T', 'A', 'A', 'T', 'C', 'T', 'A', 'C', 'T', 'A', 'C', 'T', 'T', 'T', 'T', 'A', 'G', 'T', 'A', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'G', 'T', 'C', 'T', 'T', 'G', 'A', 'G', 'A', 'C', 'G', 'G', 'A', 'G', 'T', 'C', 'T', 'T', 'G', 'C', 'T', 'C', 'T', 'G', 'T', 'C', 'G', 'C', 'C', 'C', 'A', 'G', 'G', 'C', 'T', 'G', 'G', 'A', 'G', 'G', 'G', 'C', 'A', 'G', 'T', 'G', 'G', 'C', 'G', 'C', 'A', 'A', 'T', 'G', 'T', 'T'], ['C', 'T', 'C', 'T', 'C', 'C', 'C', 'A', 'A', 'C', 'C', 'A', 'G', 'T', 'G', 'T', 'C', 'T', 'T', 'A', 'C', 'T', 'T', 'T', 'C', 'T', 'A', 'A', 'A', 'G', 'A', 'A', 'G', 'G', 'G', 'A', 'A', 'T', 'G', 'T', 'C', 'C', 'A', 'G', 'A', 'G', 'A', 'G', 'T', 'T', 'G', 'G', 'T', 'G', 'A', 'C', 'T', 'T', 'G', 'T', 'T', 'G', 'T', 'G', 'T', 'G', 'T', 'G', 'G', 'A', 'C', 'A', 'C', 'A', 'G', 'A', 'G', 'G', 'T', 'G', 'G', 'G', 'G', 'A', 'A', 'C', 'C', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'G', 'T', 'G', 'A', 'C', 'C', 'G', 'T', 'T', 'C', 'C', 'T', 'A', 'A', 'C', 'C', 'C', 'A', 'G', 'G', 'G', 'G', 'A', 'T', 'A', 'C', 'T', 'G', 'T', 'T', 'C', 'A', 'G', 'G', 'T', 'G', 'A', 'C', 'A', 'G', 'C', 'T', 'C', 'A', 'T', 'T', 'A', 'A', 'T', 'T', 'G', 'T', 'A', 'G', 'A', 'G', 'T', 'G', 'A', 'T', 'G', 'G', 'G', 'C', 'A', 'A', 'C', 'T', 'C', 'C', 'C', 'G', 'A', 'G', 'C', 'A', 'G', 'C', 'C', 'C', 'A', 'G', 'A', 'A', 'T', 'G', 'C', 'T', 'T', 'G', 'G', 'T', 'T', 'T', 'G', 'C', 'T', 'G', 'G', 'T', 'A', 'C', 'T', 'T', 'G', 'C', 'A', 'G', 'G', 'T', 'T', 'C', 'C', 'C', 'T', 'C', 'T', 'G', 'T', 'G', 'G', 'G', 'A', 'A', 'A', 'G', 'C', 'C', 'C', 'A', 'T', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'G', 'C', 'T', 'G', 'T', 'C', 'A', 'C', 'T', 'C', 'T', 'C', 'A', 'G', 'G', 'G', 'G', 'G'], ['T', 'G', 'G', 'G', 'A', 'T', 'T', 'T', 'C', 'A', 'C', 'T', 'G', 'T', 'C', 'C', 'C', 'T', 'A', 'A', 'G', 'A', 'C', 'A', 'G', 'G', 'T', 'A', 'T', 'G', 'C', 'T', 'C', 'G', 'C', 'C', 'T', 'T', 'C', 'A', 'A', 'C', 'T', 'A', 'C', 'A', 'T', 'A', 'T', 'G', 'G', 'A', 'A', 'G', 'A', 'A', 'A', 'G', 'A', 'T', 'T', 'T', 'A', 'C', 'A', 'G', 'A', 'C', 'C', 'A', 'A', 'A', 'G', 'T', 'C', 'T', 'G', 'C', 'T', 'G', 'T', 'T', 'C', 'T', 'T', 'C', 'C', 'C', 'T', 'T', 'T', 'T', 'T', 'C', 'A', 'G', 'A', 'G', 'C', 'A', 'G', 'G', 'A', 'A', 'A', 'T', 'T', 'G', 'A', 'A', 'G', 'C', 'C', 'C', 'C', 'T', 'T', 'C', 'C', 'T', 'C', 'C', 'A', 'G', 'G', 'C', 'C', 'A', 'C', 'T', 'C', 'C', 'C', 'A', 'A', 'C', 'T', 'C', 'C', 'A', 'G', 'G', 'C', 'T', 'A', 'T', 'C', 'C', 'C', 'A', 'G', 'G', 'C', 'T', 'C', 'C', 'C', 'A', 'A', 'A', 'T', 'G', 'C', 'C', 'C', 'A', 'G', 'G', 'A', 'G', 'T', 'T', 'C', 'T', 'G', 'G', 'A', 'G', 'C', 'C', 'A', 'C', 'T', 'A', 'A', 'G', 'C', 'A', 'G', 'G', 'T', 'G', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'A', 'G', 'C', 'A', 'G', 'A', 'T', 'T', 'C', 'C', 'A', 'T', 'G', 'G', 'G', 'T', 'G', 'C', 'C', 'C', 'A', 'C', 'A', 'A', 'G', 'C', 'A', 'G', 'A', 'C', 'A', 'G', 'A', 'C', 'T', 'T', 'T', 'T', 'C', 'C', 'T', 'T', 'C', 'A', 'G', 'G', 'G', 'G', 'A', 'G', 'A', 'T'], ['T', 'C', 'C', 'T', 'C', 'T', 'T', 'C', 'A', 'T', 'C', 'A', 'T', 'C', 'G', 'T', 'G', 'C', 'C', 'T', 'A', 'T', 'C', 'T', 'T', 'C', 'C', 'T', 'G', 'C', 'T', 'G', 'C', 'T', 'G', 'G', 'A', 'C', 'A', 'A', 'G', 'G', 'T', 'G', 'A', 'T', 'C', 'A', 'G', 'G', 'G', 'G', 'A', 'C', 'G', 'G', 'G', 'G', 'G', 'A', 'A', 'G', 'C', 'C', 'T', 'T', 'G', 'G', 'G', 'G', 'G', 'A', 'C', 'C', 'G', 'C', 'A', 'G', 'A', 'G', 'G', 'A', 'G', 'G', 'C', 'C', 'A', 'C', 'C', 'G', 'C', 'A', 'T', 'A', 'G', 'G', 'C', 'C', 'A', 'G', 'G', 'C', 'A', 'T', 'A', 'T', 'G', 'C', 'A', 'G', 'G', 'G', 'T', 'C', 'T', 'C', 'C', 'A', 'T', 'C', 'T', 'C', 'C', 'C', 'C', 'A', 'G', 'C', 'T', 'C', 'T', 'C', 'G', 'T', 'T', 'G', 'T', 'G', 'G', 'C', 'C', 'T', 'T', 'C', 'T', 'T', 'G', 'G', 'T', 'C', 'C', 'A', 'G', 'C', 'C', 'T', 'G', 'T', 'C', 'C', 'C', 'C', 'A', 'C', 'T', 'G', 'G', 'C', 'T', 'C', 'A', 'C', 'C', 'A', 'A', 'T', 'T', 'C', 'A', 'A', 'T', 'C', 'A', 'T', 'T', 'C', 'C', 'T', 'T', 'C', 'C', 'T', 'T', 'C', 'C', 'T', 'T', 'C', 'C', 'T', 'T', 'C', 'A', 'T', 'T', 'C', 'A', 'G', 'C', 'T', 'G', 'T', 'T', 'C', 'T', 'T', 'G', 'C', 'A', 'G', 'A', 'A', 'T', 'G', 'C', 'A', 'C', 'C', 'T', 'C', 'A', 'C', 'T', 'C', 'C', 'T', 'G', 'A', 'C', 'C', 'C', 'C', 'T', 'C', 'A', 'C', 'C', 'C', 'C', 'T', 'C'], ['G', 'G', 'A', 'T', 'T', 'T', 'C', 'A', 'C', 'A', 'T', 'A', 'C', 'T', 'G', 'C', 'A', 'T', 'C', 'T', 'C', 'C', 'T', 'T', 'C', 'A', 'A', 'C', 'A', 'A', 'G', 'G', 'A', 'T', 'C', 'T', 'G', 'C', 'T', 'G', 'A', 'C', 'C', 'T', 'G', 'C', 'T', 'G', 'G', 'G', 'A', 'T', 'C', 'C', 'A', 'G', 'A', 'G', 'G', 'A', 'G', 'A', 'A', 'T', 'A', 'A', 'G', 'A', 'T', 'G', 'G', 'C', 'C', 'C', 'C', 'T', 'T', 'G', 'C', 'G', 'A', 'A', 'T', 'T', 'T', 'G', 'G', 'G', 'G', 'T', 'G', 'C', 'T', 'G', 'A', 'A', 'T', 'A', 'G', 'C', 'T', 'T', 'G', 'G', 'C', 'G', 'A', 'A', 'T', 'G', 'T', 'C', 'C', 'T', 'C', 'T', 'C', 'A', 'C', 'A', 'G', 'C', 'A', 'C', 'C', 'T', 'C', 'A', 'A', 'C', 'C', 'A', 'A', 'A', 'A', 'A', 'G', 'A', 'C', 'A', 'C', 'C', 'C', 'T', 'G', 'A', 'T', 'G', 'C', 'A', 'G', 'C', 'G', 'C', 'T', 'T', 'G', 'C', 'G', 'C', 'A', 'A', 'T', 'G', 'G', 'G', 'C', 'T', 'T', 'C', 'A', 'G', 'A', 'A', 'T', 'T', 'G', 'T', 'G', 'C', 'C', 'A', 'C', 'A', 'C', 'A', 'C', 'A', 'C', 'C', 'C', 'A', 'G', 'C', 'C', 'C', 'T', 'T', 'C', 'T', 'G', 'G', 'G', 'G', 'A', 'T', 'C', 'A', 'C', 'T', 'G', 'A', 'C', 'C', 'A', 'A', 'C', 'A', 'G', 'G', 'A', 'C', 'A', 'C', 'G', 'T', 'G', 'A', 'G', 'G', 'A', 'G', 'A', 'G', 'A', 'G', 'G', 'G', 'G', 'T', 'G', 'C', 'A', 'G', 'A', 'G', 'G', 'G', 'G', 'C', 'T'], ['G', 'C', 'A', 'G', 'A', 'T', 'G', 'A', 'C', 'T', 'C', 'A', 'T', 'G', 'C', 'C', 'A', 'G', 'G', 'A', 'G', 'A', 'T', 'G', 'T', 'A', 'G', 'G', 'A', 'A', 'T', 'A', 'G', 'A', 'A', 'T', 'T', 'C', 'A', 'G', 'T', 'G', 'T', 'T', 'C', 'T', 'A', 'G', 'T', 'G', 'T', 'T', 'A', 'G', 'G', 'T', 'T', 'A', 'A', 'A', 'G', 'G', 'A', 'A', 'G', 'G', 'A', 'G', 'G', 'G', 'A', 'A', 'G', 'T', 'G', 'T', 'G', 'A', 'T', 'C', 'A', 'T', 'C', 'A', 'T', 'C', 'A', 'T', 'A', 'C', 'A', 'C', 'A', 'C', 'T', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'G', 'C', 'A', 'A', 'T', 'T', 'C', 'A', 'T', 'A', 'A', 'A', 'A', 'C', 'T', 'C', 'A', 'A', 'C', 'A', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'G', 'A', 'G', 'A', 'T', 'G', 'G', 'A', 'G', 'T', 'C', 'T', 'C', 'G', 'C', 'T', 'C', 'A', 'G', 'T', 'C', 'A', 'C', 'C', 'C', 'A', 'G', 'G', 'C', 'T', 'G', 'G', 'A', 'G', 'T', 'G', 'C', 'A', 'G', 'T', 'G', 'G', 'T', 'G', 'C', 'A', 'A', 'T', 'C', 'T', 'C', 'G', 'G', 'C', 'T', 'C', 'A', 'C', 'T', 'G', 'C', 'A', 'A', 'C', 'C', 'T', 'C', 'T', 'G', 'C', 'C', 'C', 'C', 'C', 'G', 'G', 'A', 'T', 'T', 'C', 'A', 'A', 'G', 'C', 'G', 'A', 'T', 'T', 'C', 'T', 'C', 'C', 'T', 'G', 'C', 'C', 'T', 'C', 'A', 'G', 'C', 'C', 'T', 'C', 'C', 'C', 'A', 'A', 'G', 'T', 'A', 'G', 'C', 'T', 'A', 'G', 'G', 'A'], ['T', 'T', 'G', 'G', 'A', 'A', 'G', 'A', 'C', 'G', 'T', 'C', 'A', 'T', 'T', 'T', 'C', 'A', 'A', 'G', 'T', 'G', 'C', 'T', 'C', 'T', 'C', 'C', 'C', 'T', 'C', 'C', 'C', 'A', 'C', 'C', 'C', 'C', 'A', 'C', 'C', 'T', 'C', 'T', 'T', 'G', 'G', 'G', 'G', 'T', 'A', 'A', 'G', 'G', 'C', 'C', 'T', 'T', 'T', 'C', 'C', 'T', 'A', 'A', 'G', 'C', 'T', 'A', 'C', 'C', 'C', 'C', 'T', 'T', 'G', 'G', 'G', 'T', 'C', 'C', 'C', 'T', 'A', 'G', 'C', 'C', 'T', 'A', 'A', 'G', 'A', 'A', 'A', 'C', 'A', 'A', 'G', 'G', 'G', 'G', 'G', 'A', 'T', 'G', 'T', 'C', 'A', 'T', 'C', 'C', 'C', 'T', 'G', 'G', 'T', 'G', 'T', 'A', 'A', 'A', 'G', 'A', 'T', 'G', 'C', 'T', 'G', 'T', 'G', 'C', 'A', 'G', 'G', 'A', 'A', 'G', 'T', 'C', 'A', 'G', 'C', 'A', 'C', 'T', 'C', 'A', 'C', 'G', 'G', 'G', 'A', 'T', 'C', 'C', 'A', 'G', 'G', 'G', 'G', 'A', 'C', 'G', 'C', 'T', 'C', 'C', 'A', 'A', 'G', 'G', 'G', 'G', 'A', 'A', 'T', 'C', 'C', 'C', 'C', 'A', 'G', 'G', 'G', 'C', 'C', 'T', 'G', 'C', 'C', 'A', 'T', 'C', 'C', 'A', 'T', 'C', 'C', 'G', 'G', 'G', 'A', 'A', 'G', 'A', 'G', 'A', 'G', 'C', 'A', 'A', 'A', 'T', 'G', 'C', 'T', 'A', 'C', 'C', 'C', 'A', 'T', 'G', 'A', 'G', 'G', 'A', 'C', 'C', 'T', 'C', 'C', 'T', 'C', 'A', 'C', 'T', 'C', 'C', 'C', 'T', 'T', 'T', 'T', 'T', 'G', 'C', 'T', 'C', 'T', 'T', 'T'], ['T', 'C', 'C', 'T', 'T', 'G', 'T', 'G', 'C', 'A', 'A', 'T', 'T', 'T', 'G', 'T', 'T', 'G', 'A', 'A', 'G', 'A', 'A', 'A', 'C', 'T', 'G', 'G', 'C', 'T', 'C', 'C', 'T', 'G', 'C', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'A', 'T', 'T', 'T', 'C', 'T', 'C', 'G', 'C', 'T', 'G', 'T', 'G', 'T', 'C', 'T', 'T', 'G', 'G', 'G', 'G', 'G', 'T', 'G', 'C', 'C', 'A', 'C', 'C', 'T', 'C', 'C', 'A', 'T', 'G', 'G', 'T', 'G', 'T', 'C', 'A', 'C', 'C', 'T', 'C', 'C', 'G', 'T', 'G', 'G', 'T', 'G', 'C', 'T', 'G', 'T', 'G', 'A', 'G', 'T', 'G', 'T', 'G', 'T', 'G', 'C', 'T', 'T', 'T', 'G', 'T', 'G', 'T', 'T', 'T', 'C', 'T', 'T', 'G', 'T', 'A', 'A', 'A', 'T', 'T', 'G', 'G', 'T', 'C', 'G', 'T', 'T', 'G', 'G', 'A', 'G', 'C', 'C', 'G', 'A', 'C', 'A', 'T', 'C', 'C', 'C', 'A', 'T', 'T', 'G', 'T', 'C', 'C', 'C', 'A', 'G', 'A', 'G', 'G', 'T', 'T', 'G', 'T', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'G', 'G', 'C', 'A', 'C', 'T', 'G', 'G', 'C', 'C', 'T', 'A', 'G', 'G', 'T', 'G', 'T', 'A', 'G', 'A', 'T', 'G', 'T', 'C', 'A', 'T', 'C', 'A', 'G', 'C', 'T', 'C', 'A', 'G', 'G', 'G', 'C', 'C', 'C', 'C', 'C', 'T', 'G', 'C', 'T', 'C', 'T', 'A', 'A', 'A', 'G', 'G', 'C', 'C', 'A', 'C', 'T', 'T', 'C', 'T', 'G', 'G', 'T', 'G', 'C', 'T', 'G', 'G', 'T', 'T', 'G', 'C', 'C', 'A', 'C', 'T', 'C', 'A', 'C'], ['G', 'A', 'C', 'G', 'G', 'C', 'C', 'G', 'G', 'G', 'A', 'C', 'G', 'T', 'G', 'G', 'A', 'G', 'G', 'C', 'A', 'C', 'T', 'G', 'T', 'G', 'C', 'C', 'A', 'G', 'G', 'T', 'A', 'T', 'T', 'C', 'T', 'G', 'G', 'C', 'A', 'G', 'G', 'C', 'T', 'T', 'C', 'T', 'C', 'A', 'G', 'G', 'T', 'G', 'A', 'A', 'G', 'C', 'A', 'C', 'A', 'A', 'G', 'C', 'C', 'C', 'A', 'C', 'T', 'G', 'C', 'T', 'G', 'T', 'G', 'G', 'T', 'G', 'G', 'C', 'C', 'A', 'A', 'G', 'A', 'C', 'C', 'T', 'T', 'C', 'A', 'A', 'G', 'G', 'G', 'C', 'C', 'G', 'G', 'G', 'G', 'C', 'A', 'C', 'C', 'C', 'C', 'A', 'A', 'G', 'T', 'A', 'A', 'G', 'C', 'A', 'A', 'G', 'C', 'A', 'C', 'T', 'T', 'T', 'C', 'C', 'T', 'C', 'C', 'T', 'G', 'C', 'T', 'C', 'C', 'T', 'G', 'G', 'T', 'T', 'G', 'T', 'T', 'A', 'A', 'A', 'A', 'G', 'C', 'A', 'T', 'C', 'T', 'G', 'T', 'C', 'C', 'G', 'C', 'T', 'C', 'A', 'G', 'C', 'A', 'G', 'C', 'A', 'G', 'A', 'G', 'G', 'C', 'G', 'G', 'G', 'A', 'G', 'A', 'G', 'G', 'C', 'T', 'T', 'A', 'G', 'A', 'G', 'G', 'G', 'G', 'C', 'C', 'T', 'A', 'G', 'G', 'C', 'A', 'G', 'A', 'T', 'G', 'A', 'C', 'T', 'C', 'A', 'T', 'T', 'T', 'A', 'G', 'T', 'G', 'A', 'A', 'T', 'A', 'G', 'C', 'A', 'G', 'T', 'T', 'C', 'T', 'G', 'C', 'C', 'T', 'G', 'G', 'A', 'G', 'T', 'A', 'T', 'A', 'T', 'G', 'T', 'T', 'G', 'G', 'A', 'G', 'G', 'C', 'T', 'C'], ['T', 'C', 'C', 'T', 'G', 'C', 'C', 'T', 'G', 'G', 'G', 'G', 'C', 'A', 'G', 'C', 'G', 'A', 'G', 'A', 'A', 'C', 'C', 'C', 'T', 'G', 'G', 'A', 'G', 'C', 'G', 'T', 'G', 'A', 'C', 'A', 'C', 'G', 'A', 'G', 'G', 'C', 'A', 'G', 'G', 'A', 'A', 'C', 'T', 'C', 'T', 'T', 'A', 'C', 'A', 'A', 'A', 'C', 'A', 'C', 'A', 'C', 'C', 'C', 'T', 'T', 'C', 'T', 'C', 'A', 'G', 'A', 'G', 'T', 'A', 'G', 'T', 'A', 'G', 'T', 'C', 'A', 'C', 'C', 'T', 'G', 'G', 'C', 'A', 'G', 'G', 'T', 'G', 'G', 'G', 'C', 'T', 'A', 'G', 'A', 'A', 'G', 'G', 'A', 'A', 'A', 'C', 'C', 'A', 'C', 'A', 'G', 'G', 'A', 'A', 'A', 'C', 'G', 'G', 'G', 'A', 'A', 'G', 'C', 'C', 'A', 'G', 'A', 'G', 'A', 'G', 'G', 'G', 'G', 'A', 'T', 'T', 'G', 'A', 'A', 'A', 'C', 'A', 'A', 'G', 'G', 'T', 'G', 'T', 'G', 'C', 'A', 'A', 'G', 'G', 'T', 'G', 'G', 'T', 'G', 'G', 'G', 'G', 'G', 'A', 'G', 'A', 'A', 'A', 'A', 'C', 'C', 'A', 'G', 'G', 'G', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'A', 'C', 'C', 'T', 'G', 'A', 'G', 'A', 'G', 'T', 'G', 'A', 'A', 'G', 'A', 'A', 'A', 'G', 'A', 'G', 'G', 'T', 'G', 'A', 'G', 'T', 'G', 'T', 'G', 'C', 'C', 'T', 'A', 'A', 'C', 'A', 'G', 'A', 'T', 'G', 'G', 'A', 'G', 'C', 'A', 'C', 'T', 'C', 'T', 'G', 'C', 'A', 'A', 'T', 'G', 'G', 'C', 'G', 'T', 'G', 'A', 'A', 'G'], ['A', 'T', 'G', 'T', 'A', 'T', 'T', 'T', 'G', 'T', 'T', 'A', 'A', 'A', 'T', 'G', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'A', 'T', 'G', 'A', 'A', 'A', 'T', 'T', 'G', 'A', 'G', 'A', 'G', 'G', 'A', 'T', 'A', 'A', 'T', 'G', 'T', 'T', 'T', 'A', 'A', 'A', 'T', 'T', 'T', 'T', 'T', 'A', 'A', 'A', 'C', 'T', 'A', 'A', 'T', 'G', 'A', 'A', 'T', 'T', 'A', 'T', 'T', 'C', 'T', 'A', 'A', 'T', 'G', 'C', 'T', 'A', 'C', 'A', 'G', 'T', 'T', 'A', 'A', 'G', 'T', 'T', 'T', 'A', 'T', 'A', 'G', 'C', 'A', 'T', 'G', 'T', 'A', 'G', 'C', 'C', 'T', 'C', 'T', 'C', 'G', 'T', 'A', 'A', 'T', 'T', 'A', 'A', 'T', 'G', 'G', 'T', 'A', 'A', 'A', 'A', 'T', 'A', 'A', 'T', 'C', 'T', 'A', 'A', 'T', 'T', 'G', 'C', 'A', 'G', 'T', 'T', 'T', 'T', 'T', 'A', 'C', 'A', 'C', 'T', 'A', 'G', 'A', 'A', 'T', 'A', 'A', 'T', 'T', 'T', 'T', 'A', 'A', 'C', 'A', 'C', 'T', 'A', 'T', 'A', 'A', 'A', 'T', 'A', 'A', 'T', 'T', 'T', 'T', 'C', 'T', 'C', 'A', 'A', 'T', 'A', 'G', 'G', 'T', 'T', 'A', 'A', 'A', 'T', 'G', 'T', 'A', 'A', 'A', 'C', 'C', 'T', 'A', 'A', 'A', 'G', 'T', 'G', 'G', 'G', 'T', 'T', 'A', 'C', 'A', 'T', 'G', 'A', 'A', 'G', 'A', 'A', 'A', 'C', 'A', 'G', 'C', 'C', 'A', 'G', 'A', 'C', 'A', 'T', 'C', 'A', 'C', 'T', 'A', 'A', 'C', 'A', 'G', 'T', 'A', 'T', 'G', 'A', 'G', 'A', 'G', 'C', 'T', 'A'], ['T', 'C', 'C', 'A', 'G', 'C', 'C', 'C', 'T', 'C', 'G', 'G', 'G', 'G', 'T', 'G', 'C', 'G', 'G', 'T', 'A', 'G', 'A', 'G', 'T', 'C', 'T', 'A', 'G', 'G', 'G', 'G', 'C', 'T', 'G', 'C', 'A', 'G', 'G', 'C', 'C', 'A', 'G', 'G', 'G', 'A', 'A', 'G', 'G', 'G', 'G', 'G', 'A', 'G', 'G', 'C', 'T', 'C', 'T', 'G', 'G', 'A', 'G', 'C', 'A', 'G', 'T', 'C', 'G', 'G', 'C', 'C', 'T', 'G', 'A', 'G', 'C', 'C', 'T', 'G', 'A', 'T', 'A', 'G', 'A', 'G', 'A', 'G', 'G', 'G', 'G', 'C', 'C', 'T', 'T', 'C', 'T', 'C', 'C', 'A', 'G', 'G', 'T', 'G', 'T', 'C', 'A', 'G', 'G', 'G', 'A', 'C', 'G', 'T', 'G', 'G', 'T', 'A', 'T', 'C', 'T', 'G', 'A', 'A', 'G', 'G', 'C', 'C', 'A', 'T', 'G', 'A', 'C', 'G', 'G', 'T', 'G', 'G', 'A', 'C', 'A', 'G', 'G', 'G', 'A', 'G', 'T', 'T', 'C', 'C', 'C', 'T', 'G', 'A', 'G', 'A', 'T', 'G', 'A', 'A', 'T', 'C', 'T', 'G', 'G', 'A', 'A', 'T', 'C', 'G', 'G', 'T', 'G', 'A', 'C', 'A', 'C', 'C', 'C', 'A', 'T', 'G', 'A', 'C', 'C', 'C', 'T', 'C', 'A', 'C', 'G', 'A', 'C', 'C', 'C', 'T', 'G', 'G', 'A', 'A', 'G', 'G', 'G', 'G', 'G', 'C', 'A', 'A', 'C', 'C', 'T', 'G', 'G', 'A', 'A', 'G', 'C', 'C', 'A', 'A', 'G', 'G', 'T', 'C', 'A', 'C', 'C', 'A', 'T', 'G', 'C', 'T', 'G', 'T', 'G', 'A', 'G', 'T', 'G', 'T', 'C', 'T', 'G', 'C', 'C', 'A', 'G', 'C', 'C', 'G', 'G'], ['A', 'C', 'A', 'G', 'A', 'A', 'G', 'G', 'G', 'T', 'G', 'G', 'G', 'T', 'G', 'G', 'T', 'G', 'G', 'C', 'C', 'T', 'G', 'G', 'A', 'G', 'A', 'A', 'A', 'G', 'A', 'C', 'C', 'T', 'G', 'C', 'T', 'T', 'T', 'G', 'G', 'G', 'T', 'C', 'A', 'G', 'C', 'T', 'T', 'G', 'G', 'G', 'A', 'T', 'G', 'A', 'G', 'A', 'A', 'T', 'G', 'C', 'A', 'T', 'C', 'C', 'T', 'T', 'C', 'A', 'G', 'C', 'C', 'A', 'C', 'T', 'T', 'G', 'G', 'C', 'C', 'A', 'C', 'C', 'A', 'A', 'C', 'A', 'C', 'C', 'C', 'C', 'A', 'G', 'C', 'C', 'C', 'A', 'T', 'C', 'T', 'G', 'C', 'T', 'A', 'G', 'G', 'C', 'A', 'T', 'G', 'T', 'G', 'G', 'A', 'G', 'G', 'G', 'C', 'A', 'G', 'G', 'A', 'C', 'T', 'T', 'T', 'G', 'A', 'C', 'T', 'G', 'G', 'T', 'A', 'T', 'T', 'A', 'G', 'G', 'T', 'T', 'T', 'C', 'T', 'T', 'T', 'T', 'T', 'C', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'G', 'C', 'C', 'C', 'A', 'G', 'T', 'T', 'G', 'T', 'G', 'C', 'C', 'A', 'T', 'G', 'G', 'C', 'A', 'T', 'G', 'A', 'G', 'G', 'T', 'T', 'T', 'C', 'T', 'G', 'A', 'T', 'G', 'C', 'C', 'A', 'G', 'G', 'G', 'C', 'A', 'G', 'G', 'G', 'C', 'T', 'G', 'G', 'C', 'C', 'A', 'G', 'A', 'A', 'C', 'A', 'C', 'C', 'T', 'G', 'C', 'A', 'T', 'T', 'C', 'C', 'A', 'G', 'A', 'G', 'C', 'A', 'C', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'A', 'G', 'A', 'A', 'G', 'T', 'G', 'T', 'G', 'G', 'A']]\n",
            "Encoded sequences:\n",
            " [[1 0 0 ... 0 1 0]\n",
            " [1 0 0 ... 1 0 0]\n",
            " [0 1 0 ... 0 1 0]\n",
            " ...\n",
            " [1 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 1 ... 0 1 0]]\n",
            "\n",
            "Decoded Sequences:\n",
            " [['A' 'C' 'A' ... 'G' 'G' 'G']\n",
            " ['A' 'T' 'G' ... 'A' 'C' 'C']\n",
            " ['C' 'C' 'C' ... 'C' 'G' 'G']\n",
            " ...\n",
            " ['A' 'T' 'G' ... 'C' 'G' 'C']\n",
            " ['T' 'A' 'T' ... 'C' 'G' 'C']\n",
            " ['G' 'G' 'G' ... 'A' 'G' 'G']]\n",
            "\n",
            "Are the original and decoded sequences equivalent? True\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def one_hot_sequence_encoder(sequence_series):\n",
        "    \"\"\"\n",
        "    Creates and returns a OneHotEncoder for DNA sequences.\n",
        "\n",
        "    Parameters:\n",
        "    sequence_series (pd.Series): Series containing DNA sequences.\n",
        "\n",
        "    Returns:\n",
        "    OneHotEncoder: Fitted OneHotEncoder instance for the given sequences.\n",
        "    \"\"\"\n",
        "    # Define fixed categories for each character position\n",
        "    categories = ['A', 'C', 'G', 'T']\n",
        "\n",
        "    # Determine the sequence length (assuming all sequences have the same length)\n",
        "    sequence_length = len(sequence_series.iloc[0])\n",
        "\n",
        "    # Initialize the OneHotEncoder with fixed categories for each position\n",
        "    one_hot_encoder = OneHotEncoder(categories=[categories] * sequence_length,\n",
        "                                    handle_unknown='ignore',\n",
        "                                    dtype=int,\n",
        "                                    sparse_output=False)\n",
        "\n",
        "    # Fit the encoder to the sequences\n",
        "    one_hot_encoder.fit(sequence_series.apply(list).tolist())\n",
        "\n",
        "    return one_hot_encoder\n",
        "\n",
        "\n",
        "encoder = one_hot_sequence_encoder(df['sequence'])\n",
        "\n",
        "# Encode sequences\n",
        "encoded_sequences = encoder.transform(df['sequence'].apply(list).tolist())\n",
        "\n",
        "# Decode sequences\n",
        "decoded_sequences = encoder.inverse_transform(encoded_sequences)\n",
        "\n",
        "# Check equivalence\n",
        "is_equivalent = (decoded_sequences == df['sequence'].apply(list).tolist()).all()\n",
        "\n",
        "print(\"Original sequences: \\n\", df['sequence'].apply(list).tolist()[:20])\n",
        "print(\"Encoded sequences:\\n\", encoded_sequences)\n",
        "print(\"\\nDecoded Sequences:\\n\", decoded_sequences)\n",
        "print(\"\\nAre the original and decoded sequences equivalent?\", is_equivalent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtVSvG-vEYpC",
        "outputId": "26431b89-148e-45cf-982c-e91199a6b1e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are all encoded sequences divisible by 4? True\n",
            "Are all sequence lengths equal? True\n",
            "Length of sequences: 251\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'df' and 'encoded_sequences' are already defined as in your provided code\n",
        "\n",
        "# Check if all encoded sequences lengths are divisible by 4 and print out if they are all equal\n",
        "sequence_lengths = [len(seq) for seq in encoded_sequences]\n",
        "\n",
        "all_divisible_by_4 = all(length % 4 == 0 for length in sequence_lengths)\n",
        "print(\"Are all encoded sequences divisible by 4?\", all_divisible_by_4)\n",
        "\n",
        "\n",
        "if all_divisible_by_4:\n",
        "    all_lengths_equal = all(length == sequence_lengths[0] for length in sequence_lengths)\n",
        "    print(\"Are all sequence lengths equal?\", all_lengths_equal)\n",
        "\n",
        "    # Calculate and print the length of the original sequences\n",
        "    if all_lengths_equal:\n",
        "      print(\"Length of sequences:\", sequence_lengths[0] // 4)\n",
        "\n",
        "    # Add a new column to the dataframe with the lengths of the original sequences.\n",
        "    df['sequence_length'] = sequence_lengths[0] // 4\n",
        "\n",
        "#Example of accessing the sequence lengths\n",
        "#print(\"Sequence lengths in df:\", df['sequence_length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DclkAGGsGCeX"
      },
      "outputs": [],
      "source": [
        "data = encoded_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtLJFlXl035o"
      },
      "source": [
        "## SimplePCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yCuZc69GpRJ"
      },
      "outputs": [],
      "source": [
        "class SimplePCA:\n",
        "    def __init__(self, n_components):\n",
        "        \"\"\"\n",
        "        Initialize PCA with the number of principal components.\n",
        "\n",
        "        Parameters:\n",
        "        n_components (int): Number of principal components to keep.\n",
        "        \"\"\"\n",
        "        self.n_components = n_components  # Number of principal components to keep\n",
        "        self.mean = None  # Mean of the input data\n",
        "        self.components = None  # Principal components (eigenvectors)\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Fit the PCA model to the data.\n",
        "\n",
        "        Parameters:\n",
        "        X (np.ndarray): Input data matrix with shape (n_samples, n_features).\n",
        "        \"\"\"\n",
        "        # Step 1: Center the data by subtracting the mean\n",
        "        self.mean = np.mean(X, axis=0)  # Compute the mean of each feature\n",
        "        X_centered = X - self.mean  # Center the data\n",
        "\n",
        "        # Step 2: Compute the covariance matrix\n",
        "        covariance_matrix = np.cov(X_centered, rowvar=False)  # Covariance matrix\n",
        "\n",
        "        # Step 3: Compute the eigenvalues and eigenvectors\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)  # Eigen decomposition using eigh for symmetric matrices\n",
        "\n",
        "        # Step 4: Sort eigenvectors by eigenvalues in descending order\n",
        "        sorted_indices = np.argsort(eigenvalues)[::-1]  # Indices of sorted eigenvalues\n",
        "        self.components = eigenvectors[:, sorted_indices[:self.n_components]]  # Top components\n",
        "\n",
        "    def _encode(self, X):\n",
        "        \"\"\"\n",
        "        Project the data onto the principal components (latent space).\n",
        "\n",
        "        Parameters:\n",
        "        X (np.ndarray): Input data matrix with shape (n_samples, n_features).\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Transformed data in the latent space.\n",
        "        \"\"\"\n",
        "        X_centered = X - self.mean  # Center the data\n",
        "        return np.dot(X_centered, self.components)  # Project onto the principal components\n",
        "\n",
        "    def _decode(self, Z):\n",
        "        \"\"\"\n",
        "        Reconstruct the original data from the latent representation.\n",
        "\n",
        "        Parameters:\n",
        "        Z (np.ndarray): Latent representation of the data.\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Reconstructed data in the original space.\n",
        "        \"\"\"\n",
        "        return np.dot(Z, self.components.T) + self.mean  # Project back to original space\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform the data using the encoder.\n",
        "\n",
        "        Parameters:\n",
        "        X (np.ndarray): Input data matrix with shape (n_samples, n_features).\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Transformed data in the latent space.\n",
        "        \"\"\"\n",
        "        return self._encode(X)  # Encode the data to latent space\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        \"\"\"\n",
        "        Fit the PCA model and transform the data in one step.\n",
        "\n",
        "        Parameters:\n",
        "        X (np.ndarray): Input data matrix with shape (n_samples, n_features).\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Transformed data in the latent space.\n",
        "        \"\"\"\n",
        "        self.fit(X)  # Fit the model\n",
        "        return self.transform(X)  # Transform the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Cc6BoCgsRX",
        "outputId": "65253f8e-7d5e-498d-dd50-9684d077c9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data Shape: (27097, 1004)\n",
            "Reduced Data Shape: (27097, 2)\n",
            "Reconstructed Data Shape: (27097, 1004)\n",
            "Reconstructed Data:\n",
            " [[0.23405211 0.22989363 0.33168709 ... 0.24791748 0.36568574 0.17303996]\n",
            " [0.28420048 0.192248   0.20963985 ... 0.19645512 0.22256865 0.30349578]\n",
            " [0.1651022  0.34325704 0.30716904 ... 0.33306012 0.34516367 0.16872342]\n",
            " ...\n",
            " [0.21936379 0.26889721 0.28009107 ... 0.2695241  0.3089194  0.21432839]\n",
            " [0.14112689 0.36577753 0.35139902 ... 0.35871977 0.39763348 0.11920528]\n",
            " [0.15470422 0.34608316 0.34802045 ... 0.3425677  0.39240241 0.12752477]]\n"
          ]
        }
      ],
      "source": [
        "    # Create dummy data (e.g., 100 samples, 5 features)\n",
        "    np.random.seed(0)\n",
        "\n",
        "    # Create and fit the PCA model\n",
        "    pca = SimplePCA(n_components=2)  # Reduce to 2 dimensions\n",
        "    reduced_data = pca.fit_transform(data)  # Fit and transform the data\n",
        "\n",
        "    # Reconstruct the original data from the reduced representation\n",
        "    reconstructed_data = pca._decode(reduced_data)\n",
        "\n",
        "    print(\"Original Data Shape:\", data.shape)\n",
        "    print(\"Reduced Data Shape:\", reduced_data.shape)\n",
        "    print(\"Reconstructed Data Shape:\", reconstructed_data.shape)\n",
        "    print(\"Reconstructed Data:\\n\", reconstructed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnjUdft6i4Ra"
      },
      "source": [
        "### PCA to Sequence Predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sfWX7-kakmJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # Subtract max for numerical stability\n",
        "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "def predict_sequence(reconstructed_data):\n",
        "    # Assuming reconstructed_data is a NumPy array where each row represents a sequence\n",
        "    # and each four columns represent a letter.\n",
        "    num_sequences = reconstructed_data.shape[0]\n",
        "    sequence_length = reconstructed_data.shape[1] // 4  # Calculate the sequence length\n",
        "    predicted_sequences = []\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        sequence_probs = reconstructed_data[i].reshape(sequence_length, 4)  # Reshape for softmax per letter\n",
        "        # Apply softmax\n",
        "        probabilities = softmax(sequence_probs)\n",
        "        # Get hard predictions (indices of max probability)\n",
        "        hard_predictions = np.argmax(probabilities, axis=1)\n",
        "\n",
        "        # Map indices back to characters\n",
        "        characters = ['A', 'C', 'G', 'T']\n",
        "        predicted_sequence = ''.join(characters[idx] for idx in hard_predictions)\n",
        "        predicted_sequences.append(predicted_sequence)\n",
        "\n",
        "    return predicted_sequences\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2_u_tpbb4B5",
        "outputId": "24103c48-df1d-4a32-e483-14c375542062"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG',\n",
              " 'TTTTTTTTTTTTTTTTTTTTTTTATTTTTTTTTTTTTTTTTTTTTTTTTTATTTAATTTTATTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTATTTTTTTTTTTTTTTTTTTTTTATTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTATTATAATTTTTTTTTTTTTTTTTTTATTTATATTTTTTTTTTTTTTTTTTTTT',\n",
              " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCGCCAGGGGCGGCGGCGGGCCGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCGGGG',\n",
              " 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG',\n",
              " 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCAGGCCCCCCCCCCCCCCGCCGGGGGCGGGGCCCCCCCCCCCCCCCCCCCCC',\n",
              " 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG',\n",
              " 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG',\n",
              " 'TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTATTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTATTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTATTATATTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT',\n",
              " 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG',\n",
              " 'CCCCCCCCCCTCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCTCCCCCCCCCCCCCCCCCCCCCCCTCAGTTTCTCCCCCCCCCCCCCCCGGGCCGGGCCCCCCTTCCCCCCCCCCCCC']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example usage (assuming 'reconstructed_data' is available)\n",
        "# Assuming reconstructed_data is available from previous code execution\n",
        "predicted_seqs = predict_sequence(reconstructed_data)\n",
        "predicted_seqs[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag-kVIOlzhvJ"
      },
      "source": [
        "## Simple Linear AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwXTNSfkziqj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SimpleLinearAutoencoder:\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        # Initialize the autoencoder with input and latent dimensions\n",
        "        self.input_dim = input_dim  # Dimension of input data\n",
        "        self.latent_dim = latent_dim  # Dimension of latent space (z)\n",
        "\n",
        "        # Weights for the encoder (e) and decoder (d)\n",
        "        self.weights_e = np.random.randn(input_dim, latent_dim) * 0.01  # Encoder weights\n",
        "        self.weights_d = np.random.randn(latent_dim, input_dim) * 0.01  # Decoder weights\n",
        "\n",
        "    def encode(self, X):\n",
        "        # Encode input data to latent space\n",
        "        return np.dot(X, self.weights_e)  # Linear transformation to latent space\n",
        "\n",
        "    def decode(self, z):\n",
        "        # Decode latent space back to original space\n",
        "        return np.dot(z, self.weights_d)  # Linear transformation to reconstruct input\n",
        "\n",
        "    def fit(self, X, epochs=1000, learning_rate=0.01):\n",
        "        # Train the autoencoder using gradient descent\n",
        "        for epoch in range(epochs):\n",
        "            # Encode input data\n",
        "            z = self.encode(X)  # Latent representation\n",
        "\n",
        "            # Decode to reconstruct input\n",
        "            X_hat = self.decode(z)  # Reconstructed input\n",
        "\n",
        "            # Calculate the loss (mean squared error)\n",
        "            loss = np.mean((X - X_hat) ** 2)\n",
        "\n",
        "            # Compute gradients for encoder and decoder weights\n",
        "            d_loss = -2 * (X - X_hat) / X.shape[0]  # Gradient of loss w.r.t reconstruction\n",
        "            grad_d = np.dot(z.T, d_loss)  # Gradient for decoder weights\n",
        "            grad_e = np.dot(X.T, np.dot(d_loss, self.weights_d.T))  # Gradient for encoder weights\n",
        "\n",
        "            # Update weights using gradient descent\n",
        "            self.weights_d -= learning_rate * grad_d  # Update decoder weights\n",
        "            self.weights_e -= learning_rate * grad_e  # Update encoder weights\n",
        "\n",
        "            # Print the loss every 100 epochs\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict using the autoencoder (reconstruct input)\n",
        "        z = self.encode(X)  # Encode input to latent space\n",
        "        return self.decode(z)  # Decode back to original space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIPLWM7Yzlmj"
      },
      "outputs": [],
      "source": [
        "execute_slow_code = False\n",
        "if execute_slow_code:\n",
        "    # Create and train the autoencoder\n",
        "    num_features = data.shape[1]\n",
        "    autoencoder = SimpleLinearAutoencoder(input_dim=num_features, latent_dim=2)\n",
        "    autoencoder.fit(data, epochs=1000, learning_rate=0.01)\n",
        "\n",
        "    # Predict (reconstruct) the input data\n",
        "    reconstructed_data = autoencoder.predict(data)\n",
        "\n",
        "    print(\"Original Data:\\n\", data)\n",
        "    print(\"Reconstructed Data:\\n\", reconstructed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuflKwO0jZ6a"
      },
      "source": [
        "## Two Layer AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUpMjCun2S9X"
      },
      "outputs": [],
      "source": [
        "class TwoLayerAutoencoder:\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        # Initialize the autoencoder with input and hidden layer dimensions\n",
        "        self.input_dim = input_dim  # Dimension of input data\n",
        "        self.hidden_dim = hidden_dim  # Dimension of hidden layer\n",
        "        # Initialize weights and biases for encoder and decoder\n",
        "        self.W1 = np.random.randn(input_dim, hidden_dim) * 0.01  # Weights for encoder\n",
        "        self.b1 = np.zeros((1, hidden_dim))  # Bias for encoder\n",
        "        self.W2 = np.random.randn(hidden_dim, input_dim) * 0.01  # Weights for decoder\n",
        "        self.b2 = np.zeros((1, input_dim))  # Bias for decoder\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        \"\"\"Sigmoid activation function.\"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def _sigmoid_derivative(self, x):\n",
        "        \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def fit(self, X, epochs=1000, learning_rate=0.01):\n",
        "        # Fit the autoencoder model to the data\n",
        "        for epoch in range(epochs):\n",
        "            # Forward pass (encoding)\n",
        "            hidden = self._sigmoid(np.dot(X, self.W1) + self.b1)  # Hidden layer output (encoder)\n",
        "            # Forward pass (decoding)\n",
        "            output = self._sigmoid(np.dot(hidden, self.W2) + self.b2)  # Reconstructed output (decoder)\n",
        "\n",
        "            # Calculate the reconstruction error\n",
        "            error = output - X  # Difference between output and original input\n",
        "            # Backpropagation\n",
        "            output_gradient = error * self._sigmoid_derivative(output)  # Gradient for output layer\n",
        "\n",
        "            # Update decoder weights and biases\n",
        "            self.W2 -= learning_rate * np.dot(hidden.T, output_gradient)  # Update W2\n",
        "            self.b2 -= learning_rate * np.sum(output_gradient, axis=0, keepdims=True)  # Update b2\n",
        "\n",
        "            # Calculate hidden layer error\n",
        "            hidden_error = np.dot(output_gradient, self.W2.T)  # Backpropagated error to hidden layer\n",
        "            hidden_gradient = hidden_error * self._sigmoid_derivative(hidden)  # Gradient for hidden layer\n",
        "\n",
        "            # Update encoder weights and biases\n",
        "            self.W1 -= learning_rate * np.dot(X.T, hidden_gradient)  # Update W1\n",
        "            self.b1 -= learning_rate * np.sum(hidden_gradient, axis=0, keepdims=True)  # Update b1\n",
        "\n",
        "            # Optional: print the error at intervals\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean(np.square(error))  # Mean squared error\n",
        "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Reconstruct the input data from the encoded representation.\"\"\"\n",
        "        hidden = self._sigmoid(np.dot(X, self.W1) + self.b1)  # Encode the input\n",
        "        output = self._sigmoid(np.dot(hidden, self.W2) + self.b2)  # Decode the hidden representation\n",
        "        return output  # Return the reconstructed data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-JDCPJT2Tb5"
      },
      "outputs": [],
      "source": [
        "execute_slow_code = False\n",
        "if execute_slow_code:\n",
        "    # Create and fit the autoencoder model\n",
        "    num_features = data.shape[1]\n",
        "    autoencoder = TwoLayerAutoencoder(input_dim=num_features, hidden_dim=3)  # 3-dimensional hidden layer\n",
        "    autoencoder.fit(data, epochs=1000, learning_rate=0.01)  # Fit the model\n",
        "\n",
        "    # Reconstruct the original data using the autoencoder\n",
        "    reconstructed_data = autoencoder.predict(data)\n",
        "\n",
        "    print(\"Original Data Shape:\", data.shape)\n",
        "    print(\"Reconstructed Data Shape:\", reconstructed_data.shape)\n",
        "    print(\"Reconstructed Data:\\n\", reconstructed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ6o3YkklxMS"
      },
      "source": [
        "## Keras AutoEncoder\n",
        "\n",
        "This is a keras based autoencoder. Please change the backend runtime to the best GPU/TPU.\n",
        "\n",
        "You can read more on TPUs [here](https://chatgpt.com/share/67227788-185c-800c-900b-78579167b503)\n",
        "\n",
        "\n",
        "You can read through docs and change the backend to tensorflow, pytorch or jax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbcF99welzdy"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dims):\n",
        "    \"\"\"\n",
        "    Create an autoencoder model with variable hidden layers.\n",
        "\n",
        "    Parameters:\n",
        "    input_dim (int): Dimension of the input data.\n",
        "    encoding_dims (list): List of integers representing the number of neurons in each hidden layer.\n",
        "\n",
        "    Returns:\n",
        "    Model: Compiled autoencoder model.\n",
        "    \"\"\"\n",
        "    # Encoder\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    x = input_layer\n",
        "    for dim in encoding_dims:\n",
        "        x = Dense(dim, activation='relu')(x)\n",
        "\n",
        "    # Decoder\n",
        "    for dim in reversed(encoding_dims[:-1]):\n",
        "        x = Dense(dim, activation='relu')(x)\n",
        "    decoded = Dense(input_dim, activation='softmax')(x)\n",
        "\n",
        "    # Autoencoder\n",
        "    autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvUiDkw4m6q2"
      },
      "source": [
        "### Example Without Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_uhZ-vOsUxP",
        "outputId": "6d0c2e30-00fc-4749-8dc4-a9d9e1b263f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.7414 - f1_score: 0.8715 - loss: 379726420975045050368.0000 - precision_1: 0.2642 - recall_1: 0.0010 - val_accuracy: 0.7492 - val_f1_score: 0.8896 - val_loss: 7688467033803385208832.0000 - val_precision_1: 0.1804 - val_recall_1: 7.1890e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8713 - loss: 15634427376301678526464.0000 - precision_1: 0.2691 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 35397347315210350755840.0000 - val_precision_1: 0.3201 - val_recall_1: 0.0013\n",
            "Epoch 3/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8727 - loss: 45814736203271729315840.0000 - precision_1: 0.2670 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 60274974951626210541568.0000 - val_precision_1: 0.3373 - val_recall_1: 0.0013\n",
            "Epoch 4/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8747 - loss: 72284647516741446926336.0000 - precision_1: 0.2690 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 91171744554816030900224.0000 - val_precision_1: 0.3072 - val_recall_1: 0.0012\n",
            "Epoch 5/50\n",
            "\u001b[1m674/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - f1_score: 0.8741 - loss: 103647418084174174617600.0000 - precision_1: 0.2685 - recall_1: 0.0011Epoch 5: loss = 1.1188014231819552e+23, val_loss = 1.3014580565808776e+23\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8741 - loss: 103707910434369015119872.0000 - precision_1: 0.2685 - recall_1: 0.0011 - val_accuracy: 0.7494 - val_f1_score: 0.8896 - val_loss: 130145805658087755874304.0000 - val_precision_1: 0.3480 - val_recall_1: 0.0014\n",
            "Epoch 6/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8710 - loss: 139222882764647028490240.0000 - precision_1: 0.2769 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 147502210247612400926720.0000 - val_precision_1: 0.3371 - val_recall_1: 0.0013\n",
            "Epoch 7/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8723 - loss: 180735037509915943895040.0000 - precision_1: 0.2712 - recall_1: 0.0011 - val_accuracy: 0.7492 - val_f1_score: 0.8896 - val_loss: 184086057906251273076736.0000 - val_precision_1: 0.2299 - val_recall_1: 9.1589e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.7493 - f1_score: 0.8722 - loss: 225546484306200210964480.0000 - precision_1: 0.2715 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 227746528752967717224448.0000 - val_precision_1: 0.3371 - val_recall_1: 0.0013\n",
            "Epoch 9/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8713 - loss: 277056495116242806374400.0000 - precision_1: 0.2707 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 274939641161792087916544.0000 - val_precision_1: 0.3161 - val_recall_1: 0.0013\n",
            "Epoch 10/50\n",
            "\u001b[1m674/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8734 - loss: 335843476247386177667072.0000 - precision_1: 0.2726 - recall_1: 0.0011Epoch 10: loss = 3.7164485949956645e+23, val_loss = 4.505559954216298e+23\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8734 - loss: 336105837947278273282048.0000 - precision_1: 0.2726 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 450555995421629782949888.0000 - val_precision_1: 0.2956 - val_recall_1: 0.0012\n",
            "Epoch 11/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8717 - loss: 776054018777802570989568.0000 - precision_1: 0.2748 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 2871875874738324660813824.0000 - val_precision_1: 0.3404 - val_recall_1: 0.0014\n",
            "Epoch 12/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7493 - f1_score: 0.8698 - loss: 4359457922100034170519552.0000 - precision_1: 0.2679 - recall_1: 0.0011 - val_accuracy: 0.7492 - val_f1_score: 0.8896 - val_loss: 14557613561884853028257792.0000 - val_precision_1: 0.1875 - val_recall_1: 7.4683e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.7492 - f1_score: 0.8726 - loss: 17946567525679944765014016.0000 - precision_1: 0.2379 - recall_1: 9.4636e-04 - val_accuracy: 0.7490 - val_f1_score: 0.8896 - val_loss: 31188253776029111757570048.0000 - val_precision_1: 0.0441 - val_recall_1: 1.7568e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7492 - f1_score: 0.8728 - loss: 29317564847828207700803584.0000 - precision_1: 0.2379 - recall_1: 9.4768e-04 - val_accuracy: 0.7492 - val_f1_score: 0.8896 - val_loss: 33516032269789455580135424.0000 - val_precision_1: 0.2022 - val_recall_1: 8.0563e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m672/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8720 - loss: 31440478413591951670509568.0000 - precision_1: 0.2579 - recall_1: 0.0010Epoch 15: loss = 3.201762400126911e+25, val_loss = 3.585093812429128e+25\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8720 - loss: 31446379065852529513332736.0000 - precision_1: 0.2581 - recall_1: 0.0010 - val_accuracy: 0.7494 - val_f1_score: 0.8896 - val_loss: 35850938124291278930706432.0000 - val_precision_1: 0.4013 - val_recall_1: 0.0016\n",
            "Epoch 16/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8732 - loss: 33606661123423590607224832.0000 - precision_1: 0.3019 - recall_1: 0.0012 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 38193312604299945435987968.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 17/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8723 - loss: 35866601715852867553722368.0000 - precision_1: 0.2739 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 40546127941454331547484160.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 18/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8731 - loss: 37992549771016736744669184.0000 - precision_1: 0.2750 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 42922405231227466994941952.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 19/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8724 - loss: 40165792972142588012265472.0000 - precision_1: 0.2705 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 45298705579430694579339264.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 20/50\n",
            "\u001b[1m673/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - f1_score: 0.8683 - loss: 42384807157001331104808960.0000 - precision_1: 0.2690 - recall_1: 0.0011Epoch 20: loss = 4.2919361518455305e+25, val_loss = 4.767530568722512e+25\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8683 - loss: 42389511076740127040471040.0000 - precision_1: 0.2690 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 47675305687225119943950336.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 21/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8731 - loss: 44561605968047389888479232.0000 - precision_1: 0.2713 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 50051896571647508453785600.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 22/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8701 - loss: 46712321082973223366164480.0000 - precision_1: 0.2673 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 52428473621011841681457152.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 23/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8743 - loss: 48944829061121884995715072.0000 - precision_1: 0.2687 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 54804875426307474668388352.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 24/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8724 - loss: 51196950539906918306021376.0000 - precision_1: 0.2695 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 57180912908407651891675136.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 25/50\n",
            "\u001b[1m677/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - f1_score: 0.8755 - loss: 53250603499202910550491136.0000 - precision_1: 0.2722 - recall_1: 0.0011Epoch 25: loss = 5.3891577127218115e+25, val_loss = 5.955760986160846e+25\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8755 - loss: 53252489678784447352143872.0000 - precision_1: 0.2722 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 59557609861608464231432192.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 26/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8722 - loss: 55542832811290206853398528.0000 - precision_1: 0.2717 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 61934209969402889596043264.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 27/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8732 - loss: 57746591538799992146755584.0000 - precision_1: 0.2702 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 64310413472199730205294592.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 28/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8738 - loss: 59906774445121657051807744.0000 - precision_1: 0.2756 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 66686547799706294403727360.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 29/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8747 - loss: 62138489213275149170638848.0000 - precision_1: 0.2719 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 69063392326859696419897344.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 30/50\n",
            "\u001b[1m675/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - f1_score: 0.8717 - loss: 64416113315742085936054272.0000 - precision_1: 0.2710 - recall_1: 0.0011Epoch 30: loss = 6.486026940786285e+25, val_loss = 7.143975262698116e+25\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8717 - loss: 64418723530028515837607936.0000 - precision_1: 0.2710 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 71439752626981163560337408.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 31/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7493 - f1_score: 0.8715 - loss: 66566353427008021392785408.0000 - precision_1: 0.2667 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 73816371181519662634500096.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 32/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8743 - loss: 68603358199777490766921728.0000 - precision_1: 0.2668 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 76193137310010751385075712.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 33/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8713 - loss: 70986921953459741487267840.0000 - precision_1: 0.2775 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 78569718971061103040135168.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 34/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8747 - loss: 73046542434463578771685376.0000 - precision_1: 0.2677 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 80946415924261915379892224.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 35/50\n",
            "\u001b[1m676/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - f1_score: 0.8730 - loss: 75176675594689170817155072.0000 - precision_1: 0.2741 - recall_1: 0.0011Epoch 35: loss = 7.583369327836248e+25, val_loss = 8.332264248548885e+25\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8730 - loss: 75179580956880780071534592.0000 - precision_1: 0.2741 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 83322642485488848126083072.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 36/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8749 - loss: 77543738735797488343580672.0000 - precision_1: 0.2701 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 85699099631016702241669120.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 37/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8740 - loss: 79716193338614188527845376.0000 - precision_1: 0.2712 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 88075649010264924905013248.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 38/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8742 - loss: 81817923124652286291214336.0000 - precision_1: 0.2728 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 90451783337771489103446016.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 39/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8745 - loss: 83969007174459593959931904.0000 - precision_1: 0.2676 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 92827936112022127011430400.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 40/50\n",
            "\u001b[1m677/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8747 - loss: 86319924802817397201305600.0000 - precision_1: 0.2706 - recall_1: 0.0011Epoch 40: loss = 8.680292512627137e+25, val_loss = 9.520441170429405e+25\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8747 - loss: 86321345202111072836780032.0000 - precision_1: 0.2706 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 95204411704294054836568064.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 41/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8722 - loss: 88382556714791267570024448.0000 - precision_1: 0.2701 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 97581210114587272578859008.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 42/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8702 - loss: 90706237725524238658437120.0000 - precision_1: 0.2680 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 99957787163951605806530560.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 43/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8766 - loss: 92854185828839015703379968.0000 - precision_1: 0.2704 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 102334087512154833390927872.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 44/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8735 - loss: 95105371135362308253941760.0000 - precision_1: 0.2752 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 104710397083730097830100992.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 45/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8717 - loss: 97204232452696944182034432.0000 - precision_1: 0.2697 - recall_1: 0.0011Epoch 45: loss = 9.777478102352474e+25, val_loss = 1.0708667898518925e+26\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8717 - loss: 97205071779552297966632960.0000 - precision_1: 0.2697 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 107086678985189251704946688.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 46/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8709 - loss: 99513294418751500450791424.0000 - precision_1: 0.2758 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 109463892447224127912148992.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 47/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8740 - loss: 101657654630343940987944960.0000 - precision_1: 0.2683 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 111840054444846802674909184.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 48/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7493 - f1_score: 0.8720 - loss: 103768497107954451269812224.0000 - precision_1: 0.2734 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 114216068868516887761256448.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 49/50\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7493 - f1_score: 0.8712 - loss: 106055505991468887769612288.0000 - precision_1: 0.2704 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 116593014852762695179960320.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n",
            "Epoch 50/50\n",
            "\u001b[1m675/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7493 - f1_score: 0.8712 - loss: 108348454726575058745032704.0000 - precision_1: 0.2683 - recall_1: 0.0011Epoch 50: loss = 1.0874531797857685e+26, val_loss = 1.1896948122166259e+26\n",
            "\u001b[1m678/678\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7493 - f1_score: 0.8713 - loss: 108350797463072419858087936.0000 - precision_1: 0.2683 - recall_1: 0.0011 - val_accuracy: 0.7493 - val_f1_score: 0.8896 - val_loss: 118969481221662586150322176.0000 - val_precision_1: 0.3057 - val_recall_1: 0.0012\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x784865ea49a0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import Callback\n",
        "from keras.metrics import Precision, Recall, Accuracy\n",
        "import tensorflow as tf\n",
        "\n",
        "input_dim = data.shape[1]\n",
        "encoding_dims = [128, 64, 32]  # Example hidden layers\n",
        "autoencoder = create_autoencoder(input_dim, encoding_dims)\n",
        "\n",
        "# Initialize the RMSProp optimizer with a learning rate of 0.01\n",
        "rmsprop_optimizer = RMSprop(learning_rate=0.1)\n",
        "\n",
        "# Custom callback to print progress every 5 epochs\n",
        "class PrintProgress(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch + 1}: loss = {logs['loss']}, val_loss = {logs['val_loss']}\")\n",
        "\n",
        "# Custom metric for F1 score\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.argmax(y_true, axis=-1)\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# Compile the autoencoder with the custom optimizer and additional metrics\n",
        "autoencoder.compile(optimizer=rmsprop_optimizer, loss='categorical_crossentropy', metrics=[F1Score(), Precision(), Recall(), Accuracy()])\n",
        "\n",
        "# Train the autoencoder with the custom progress callback\n",
        "autoencoder.fit(data, data, epochs=50, batch_size=32, validation_split=0.2, callbacks=[PrintProgress()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "PzC5cFIq0ox9",
        "outputId": "0abf1ef4-3aa2-47a8-fa8b-1480d613dfed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m847/847\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# prompt: Display how the latent space of the autoencoder clusters. You can use the labels from the dataframe to color the clustering.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'autoencoder' is your trained Keras autoencoder and 'data' is your input data\n",
        "# Get the encoder part of the autoencoder\n",
        "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[-3].output) # Adjusted to get the second-to-last layer\n",
        "\n",
        "# Encode the data to get the latent space representation\n",
        "latent_space = encoder.predict(data)\n",
        "\n",
        "# Assuming 'df' is your DataFrame with labels\n",
        "labels = df['labels'].values # Access labels from your dataframe\n",
        "\n",
        "# Create a scatter plot of the latent space, coloring points by their labels\n",
        "plt.figure(figsize=(10, 8))\n",
        "for label in np.unique(labels):\n",
        "    indices = np.where(labels == label)\n",
        "    plt.scatter(latent_space[indices, 0], latent_space[indices, 1], label=label)\n",
        "\n",
        "plt.xlabel(\"Latent Dimension 1\")\n",
        "plt.ylabel(\"Latent Dimension 2\")\n",
        "plt.title(\"Latent Space Clustering\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0g-aknXtq9K"
      },
      "source": [
        "### Hyperparameter Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m6JZphUtpoN",
        "outputId": "4bdd5818-3c91-4680-ecfc-57ab964130b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwMp-CneuQej"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import Callback\n",
        "from keras.metrics import Precision, Recall, Accuracy\n",
        "import tensorflow as tf\n",
        "\n",
        "# Custom callback to print progress every 5 epochs\n",
        "class PrintProgress(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch + 1}: loss = {logs['loss']}, val_loss = {logs['val_loss']}\")\n",
        "\n",
        "# Custom metric for F1 score\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.argmax(y_true, axis=-1)\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
        "    encoding_dims = [trial.suggest_int(f'n_units_l{i}', 8, 512) for i in range(num_layers)]\n",
        "\n",
        "    # Create the autoencoder model\n",
        "    autoencoder = create_autoencoder(input_dim, encoding_dims)\n",
        "\n",
        "    # Initialize the RMSProp optimizer with the suggested learning rate\n",
        "    rmsprop_optimizer = RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the autoencoder with the custom optimizer and additional metrics\n",
        "    autoencoder.compile(optimizer=rmsprop_optimizer, loss='mse', metrics=[F1Score(), Precision(), Recall(), Accuracy()])\n",
        "\n",
        "    # Train the autoencoder with the custom progress callback\n",
        "    history = autoencoder.fit(data, data, epochs=50, batch_size=32, validation_split=0.2, callbacks=[PrintProgress()], verbose=0)\n",
        "\n",
        "    # Return the validation loss as the objective value\n",
        "    return history.history['val_loss'][-1]\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best hyperparameters: ', study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnaMCX24mpNU"
      },
      "source": [
        "### Check Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6HaHqFImonQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}